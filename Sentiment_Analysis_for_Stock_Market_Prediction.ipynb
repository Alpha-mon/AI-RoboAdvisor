{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alpha-mon/AI-RoboAdvisor/blob/main/Sentiment_Analysis_for_Stock_Market_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgn2NUhqzLle"
      },
      "outputs": [],
      "source": [
        "# 뉴스 제목, 일자 크롤링\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101&date=\"\n",
        "\n",
        "# 1. User-Agent를 설정\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# 시작 날짜와 종료 날짜 설정\n",
        "start_date = datetime.datetime.now() - datetime.timedelta(days=30)\n",
        "end_date = datetime.datetime.now() - datetime.timedelta(days=5)\n",
        "\n",
        "current_date = start_date\n",
        "\n",
        "news_data = []\n",
        "\n",
        "while current_date <= end_date:\n",
        "    # 2. 요청을 보낼 때 headers 추가\n",
        "    response = requests.get(base_url + current_date.strftime('%Y%m%d'), headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    for item in soup.select(\".cluster_text a\"):\n",
        "        title = item.text.strip()\n",
        "        if item.attrs[\"href\"].startswith(\"http\"):\n",
        "            news_url = item.attrs[\"href\"]\n",
        "        else:\n",
        "            news_url = \"https:\" + item.attrs[\"href\"]\n",
        "\n",
        "        detail_response = requests.get(news_url, headers=headers)  # headers 추가\n",
        "        detail_soup = BeautifulSoup(detail_response.text, 'html.parser')\n",
        "        date_element = detail_soup.select_one(\"span.media_end_head_info_datestamp_time\")\n",
        "        date = date_element.attrs[\"data-date-time\"].split()[0]\n",
        "\n",
        "        news_data.append({\n",
        "            'title': title,\n",
        "            'date': date\n",
        "        })\n",
        "\n",
        "        # 요청 간에 약간의 지연을 두어 IP 차단을 피하기\n",
        "        time.sleep(1.5)\n",
        "\n",
        "    # 다음 날짜로 이동\n",
        "    current_date += datetime.timedelta(days=1)\n",
        "\n",
        "# 뉴스 데이터를 날짜 순으로 정렬\n",
        "news_data_sorted = sorted(news_data, key=lambda x: x['date'])\n",
        "\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "news_df = pd.DataFrame(news_data_sorted, columns=['date', 'title'])\n",
        "\n",
        "# 시작 날짜와 종료 날짜를 문자열로 변환\n",
        "start_date_str = start_date.strftime('%Y-%m-%d')\n",
        "end_date_str = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "# 원하는 날짜 범위만 선택\n",
        "news_df = news_df[(news_df['date'] >= start_date_str) & (news_df['date'] <= end_date_str)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXlG49V01JRX",
        "outputId": "b552735f-15e7-466b-e729-199766a8e7d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsncbVAf0C4p",
        "outputId": "ef32c262-f04e-4098-f53d-ab35c06158e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          date                                          title  \\\n",
            "5   2023-09-19                          삼성전자, 3주만에 다시 '6만전자'로   \n",
            "6   2023-09-19                          삼성전자, 3주만에 다시 '6만전자'로   \n",
            "7   2023-09-19                       수요와 균형 이루는 주택공급 확대 정책 기대   \n",
            "8   2023-09-20                  주택구입자 3분의1이 받은 특례보금자리론…축소 파장은   \n",
            "9   2023-09-27                    도생·오피스텔에 기금 지원…공급부족 해소 도움될까   \n",
            "10  2023-09-27                    사라 버튼 떠나는 알렉산더 맥퀸, 후임 누가 될까   \n",
            "11  2023-09-27                             이더리움 NFT가 지갑이 된다고?   \n",
            "12  2023-10-03  ‘월클 美모’ 송혜교‧수지, 300만원 vs 1000만원 ‘여신 드레스룩’ 승자는   \n",
            "13  2023-10-03                    [데스크칼럼]반쪽 주택대책 안되려면 ‘실행’뿐이다   \n",
            "14  2023-10-04                        디폴트옵션 완전정복…당신도 연금부자 됩니다   \n",
            "15  2023-10-05                      IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "16  2023-10-05               \"에코프로 욕하려면 80만원 내세요\"…확 달라진 '종토방'   \n",
            "17  2023-10-05                      IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "18  2023-10-06                    80~1000만원대까지…시선강탈 레드카펫 ★드레스   \n",
            "19  2023-10-06                \"모두 백인 남성이네\" 명품기업 케링그룹, 욕 먹는 이유   \n",
            "20  2023-10-06                     빗썸 수수료 무료, 830 프로젝트 덕분이라고?   \n",
            "21  2023-10-11                    삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "22  2023-10-11                    삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "23  2023-10-11                            [데스크칼럼]먹거리 물가와 기후위기   \n",
            "24  2023-10-11             \"억눌렸던 욕구 폭발\"…뉴진스 '팝업스토어' 대박 이유 있었다   \n",
            "25  2023-10-11              '목욕탕 슬리퍼'가 11조원 회사로…200년을 버틴 버켄스탁   \n",
            "26  2023-10-11                뉴:홈, 당첨일 다르면 중복청약 OK…거주 의무도 꼼꼼히   \n",
            "27  2023-10-11                   마곡 3억·하남 4억대 ‘뉴홈’ 3300가구 풀린다   \n",
            "28  2023-10-11                      같이 오르내리던 매매·전세가, 이제 동행 끝?   \n",
            "29  2023-10-11                고조되는 이-팔 전쟁 우려, 코인은 정말 위기에 강한가?   \n",
            "30  2023-10-12                  \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "31  2023-10-12                  \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "32  2023-10-12              \"클수록 좋다\" SUV 판매 1위는 쏘렌토…파업 리스크 변수   \n",
            "33  2023-10-12                   지방소멸 해법 떠오른 다주택자 규제…패러다임 바뀌나   \n",
            "34  2023-10-12                 청계천 떠난 '작은 공장'이 말하는 떠나야만 했던 이유   \n",
            "35  2023-10-13          \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "36  2023-10-13                          포르셰 뽑은 30대, 인천서 확 늘었다   \n",
            "37  2023-10-13       뉴욕증시, 예상 웃돈 CPI·국채금리 상승에 일제 하락…테슬라 1.5%↓   \n",
            "38  2023-10-13          \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "39  2023-10-13                 한국 AI 경쟁력 세계 6위?…하위 굳히는 핵심 영역은   \n",
            "40  2023-10-13                    '미 국채가 안 팔린다'…증시 흔든 채권금리 급등   \n",
            "41  2023-10-13                코스피, 美 CPI 부담에 1% 하락…2456.15 마감   \n",
            "42  2023-10-13              '엔씨소프트 vs 카카오' 국민 밉상주 투표 열렸다…결과는?   \n",
            "43  2023-10-13                  550억에 인수하더니…'마흔살' KFC의 놀라운 변신   \n",
            "44  2023-10-13                 좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "45  2023-10-13                       분양가 너무 비쌌나…서울서 미분양 나온 까닭   \n",
            "\n",
            "                                    nouns  \n",
            "5                        삼성, 전자, 주, 다시, 로  \n",
            "6                        삼성, 전자, 주, 다시, 로  \n",
            "7              수요, 균형, 주택, 공급, 확대, 정책, 기대  \n",
            "8          주택, 구입, 이, 특례, 보금자리, 론, 축소, 파장  \n",
            "9        도생, 오피스텔, 기금, 지원, 공급, 부족, 해소, 도움  \n",
            "10               사라, 버튼, 알렉산더, 맥퀸, 후임, 누가  \n",
            "11                              더, 리움, 지갑  \n",
            "12             월, 모, 송혜교, 수지, 여신, 드레스, 승자  \n",
            "13             데스크, 칼럼, 반쪽, 주택, 대책, 실행, 뿐  \n",
            "14            디폴트, 옵션, 완전, 정복, 당신, 연금, 부자  \n",
            "15                   두산, 로보틱스, 상장, 첫날, 따블  \n",
            "16                에코, 프로, 욕, 내세, 확, 종, 토방  \n",
            "17                   두산, 로보틱스, 상장, 첫날, 따블  \n",
            "18                      시선, 강탈, 레드카펫, 드레스  \n",
            "19      모두, 백인, 남성, 명품, 기업, 케링, 그룹, 욕, 이유  \n",
            "20                  빗썸, 수수료, 무료, 프로젝트, 덕분  \n",
            "21           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "22           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "23               데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "24           욕구, 폭발, 뉴진스, 팝업, 스토어, 대박, 이유  \n",
            "25                     목욕탕, 슬리퍼, 회사, 버켄스탁  \n",
            "26            뉴, 홈, 당첨, 일, 중복, 청약, 거주, 의무  \n",
            "27                         마곡, 하남, 뉴홈, 가구  \n",
            "28                      매매, 전세, 이제, 동행, 끝  \n",
            "29           고조, 이, 팔, 전쟁, 우려, 코인, 정말, 위기  \n",
            "30                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "31                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "32                판매, 위, 쏘렌토, 파업, 리스크, 변수  \n",
            "33               지방, 소멸, 해법, 주택, 규제, 패러다임  \n",
            "34                      청계천, 공장, 이, 말, 이유  \n",
            "35          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "36                             포르셰, 인천, 확  \n",
            "37  뉴욕증시, 예상, 웃돈, 국채, 금리, 상승, 일제, 하락, 테슬라  \n",
            "38          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "39             한국, 경쟁력, 세계, 위, 하위, 핵심, 영역  \n",
            "40              국채, 안, 린다, 증시, 채권, 금리, 급등  \n",
            "41                        코스피, 부담, 하락, 마감  \n",
            "42             엔씨소프트, 카카오, 국민, 상주, 투표, 결과  \n",
            "43                           인수, 살, 의, 변신  \n",
            "44             좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "45                         분양, 서울, 미분, 까닭  \n"
          ]
        }
      ],
      "source": [
        "# 크롤링한 뉴스 제목 명사 추출\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "# Okt 객체 초기화\n",
        "okt = Okt()\n",
        "\n",
        "# 제목에서 명사만 추출하는 함수\n",
        "def extract_nouns(title):\n",
        "    return ', '.join(okt.nouns(title))\n",
        "\n",
        "# 'title' 열의 각 제목에 대하여 명사만 추출\n",
        "news_df['nouns'] = news_df['title'].apply(extract_nouns)\n",
        "\n",
        "print(news_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFLDnMan0OVg",
        "outputId": "6586726b-a400-4fce-f152-472c004f492b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Date  Closing  Up/Down\n",
            "0   2023-08-31  2556.27        1\n",
            "1   2023-09-01  2563.71        1\n",
            "2   2023-09-04  2584.55        0\n",
            "3   2023-09-05  2582.18        0\n",
            "4   2023-09-06  2563.34        0\n",
            "5   2023-09-07  2548.26        0\n",
            "6   2023-09-08  2547.68        1\n",
            "7   2023-09-11  2556.88        0\n",
            "8   2023-09-12  2536.58        0\n",
            "9   2023-09-13  2534.70        1\n",
            "10  2023-09-14  2572.89        1\n",
            "11  2023-09-15  2601.28        0\n",
            "12  2023-09-18  2574.72        0\n",
            "13  2023-09-19  2559.21        1\n",
            "14  2023-09-20  2559.74        0\n",
            "15  2023-09-21  2514.97        0\n",
            "16  2023-09-22  2508.13        0\n",
            "17  2023-09-25  2495.76        0\n",
            "18  2023-09-26  2462.97        1\n",
            "19  2023-09-27  2465.07        0\n",
            "20  2023-10-04  2405.69        0\n",
            "21  2023-10-05  2403.60        1\n",
            "22  2023-10-06  2408.73        0\n",
            "23  2023-10-10  2402.58        1\n",
            "24  2023-10-11  2450.08        1\n",
            "25  2023-10-12  2479.82        0\n",
            "26  2023-10-13  2456.15        0\n",
            "27  2023-10-16  2436.24        1\n",
            "28  2023-10-17  2460.17        1\n",
            "29  2023-10-18  2462.60        0\n",
            "          date  Up/Down                                     title  \\\n",
            "0   2023-09-19        1                     삼성전자, 3주만에 다시 '6만전자'로   \n",
            "1   2023-09-19        1                     삼성전자, 3주만에 다시 '6만전자'로   \n",
            "2   2023-09-19        1                  수요와 균형 이루는 주택공급 확대 정책 기대   \n",
            "3   2023-09-20        0             주택구입자 3분의1이 받은 특례보금자리론…축소 파장은   \n",
            "4   2023-09-27        0               도생·오피스텔에 기금 지원…공급부족 해소 도움될까   \n",
            "5   2023-09-27        0               사라 버튼 떠나는 알렉산더 맥퀸, 후임 누가 될까   \n",
            "6   2023-09-27        0                        이더리움 NFT가 지갑이 된다고?   \n",
            "7   2023-10-04        0                   디폴트옵션 완전정복…당신도 연금부자 됩니다   \n",
            "8   2023-10-05        1                 IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "9   2023-10-05        1          \"에코프로 욕하려면 80만원 내세요\"…확 달라진 '종토방'   \n",
            "10  2023-10-05        1                 IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "11  2023-10-06        0               80~1000만원대까지…시선강탈 레드카펫 ★드레스   \n",
            "12  2023-10-06        0           \"모두 백인 남성이네\" 명품기업 케링그룹, 욕 먹는 이유   \n",
            "13  2023-10-06        0                빗썸 수수료 무료, 830 프로젝트 덕분이라고?   \n",
            "14  2023-10-11        1               삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "15  2023-10-11        1               삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "16  2023-10-11        1                       [데스크칼럼]먹거리 물가와 기후위기   \n",
            "17  2023-10-11        1        \"억눌렸던 욕구 폭발\"…뉴진스 '팝업스토어' 대박 이유 있었다   \n",
            "18  2023-10-11        1         '목욕탕 슬리퍼'가 11조원 회사로…200년을 버틴 버켄스탁   \n",
            "19  2023-10-11        1           뉴:홈, 당첨일 다르면 중복청약 OK…거주 의무도 꼼꼼히   \n",
            "20  2023-10-11        1              마곡 3억·하남 4억대 ‘뉴홈’ 3300가구 풀린다   \n",
            "21  2023-10-11        1                 같이 오르내리던 매매·전세가, 이제 동행 끝?   \n",
            "22  2023-10-11        1           고조되는 이-팔 전쟁 우려, 코인은 정말 위기에 강한가?   \n",
            "23  2023-10-12        0             \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "24  2023-10-12        0             \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "25  2023-10-12        0         \"클수록 좋다\" SUV 판매 1위는 쏘렌토…파업 리스크 변수   \n",
            "26  2023-10-12        0              지방소멸 해법 떠오른 다주택자 규제…패러다임 바뀌나   \n",
            "27  2023-10-12        0            청계천 떠난 '작은 공장'이 말하는 떠나야만 했던 이유   \n",
            "28  2023-10-13        0     \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "29  2023-10-13        0                     포르셰 뽑은 30대, 인천서 확 늘었다   \n",
            "30  2023-10-13        0  뉴욕증시, 예상 웃돈 CPI·국채금리 상승에 일제 하락…테슬라 1.5%↓   \n",
            "31  2023-10-13        0     \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "32  2023-10-13        0            한국 AI 경쟁력 세계 6위?…하위 굳히는 핵심 영역은   \n",
            "33  2023-10-13        0               '미 국채가 안 팔린다'…증시 흔든 채권금리 급등   \n",
            "34  2023-10-13        0           코스피, 美 CPI 부담에 1% 하락…2456.15 마감   \n",
            "35  2023-10-13        0         '엔씨소프트 vs 카카오' 국민 밉상주 투표 열렸다…결과는?   \n",
            "36  2023-10-13        0             550억에 인수하더니…'마흔살' KFC의 놀라운 변신   \n",
            "37  2023-10-13        0            좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "38  2023-10-13        0                  분양가 너무 비쌌나…서울서 미분양 나온 까닭   \n",
            "\n",
            "                                    nouns  \n",
            "0                        삼성, 전자, 주, 다시, 로  \n",
            "1                        삼성, 전자, 주, 다시, 로  \n",
            "2              수요, 균형, 주택, 공급, 확대, 정책, 기대  \n",
            "3          주택, 구입, 이, 특례, 보금자리, 론, 축소, 파장  \n",
            "4        도생, 오피스텔, 기금, 지원, 공급, 부족, 해소, 도움  \n",
            "5                사라, 버튼, 알렉산더, 맥퀸, 후임, 누가  \n",
            "6                               더, 리움, 지갑  \n",
            "7             디폴트, 옵션, 완전, 정복, 당신, 연금, 부자  \n",
            "8                    두산, 로보틱스, 상장, 첫날, 따블  \n",
            "9                 에코, 프로, 욕, 내세, 확, 종, 토방  \n",
            "10                   두산, 로보틱스, 상장, 첫날, 따블  \n",
            "11                      시선, 강탈, 레드카펫, 드레스  \n",
            "12      모두, 백인, 남성, 명품, 기업, 케링, 그룹, 욕, 이유  \n",
            "13                  빗썸, 수수료, 무료, 프로젝트, 덕분  \n",
            "14           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "15           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "16               데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "17           욕구, 폭발, 뉴진스, 팝업, 스토어, 대박, 이유  \n",
            "18                     목욕탕, 슬리퍼, 회사, 버켄스탁  \n",
            "19            뉴, 홈, 당첨, 일, 중복, 청약, 거주, 의무  \n",
            "20                         마곡, 하남, 뉴홈, 가구  \n",
            "21                      매매, 전세, 이제, 동행, 끝  \n",
            "22           고조, 이, 팔, 전쟁, 우려, 코인, 정말, 위기  \n",
            "23                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "24                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "25                판매, 위, 쏘렌토, 파업, 리스크, 변수  \n",
            "26               지방, 소멸, 해법, 주택, 규제, 패러다임  \n",
            "27                      청계천, 공장, 이, 말, 이유  \n",
            "28          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "29                             포르셰, 인천, 확  \n",
            "30  뉴욕증시, 예상, 웃돈, 국채, 금리, 상승, 일제, 하락, 테슬라  \n",
            "31          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "32             한국, 경쟁력, 세계, 위, 하위, 핵심, 영역  \n",
            "33              국채, 안, 린다, 증시, 채권, 금리, 급등  \n",
            "34                        코스피, 부담, 하락, 마감  \n",
            "35             엔씨소프트, 카카오, 국민, 상주, 투표, 결과  \n",
            "36                           인수, 살, 의, 변신  \n",
            "37             좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "38                         분양, 서울, 미분, 까닭  \n"
          ]
        }
      ],
      "source": [
        "# 코스피 등락율 - 뉴스\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def get_kospi_closing_prices():\n",
        "    url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSPI\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    kospi_closings = []\n",
        "\n",
        "    for i in range(1, 7):\n",
        "        response = requests.get(url + f\"&page={i}\", headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        dates = soup.select(\".date\")\n",
        "        closings = soup.select(\".number_1\")\n",
        "\n",
        "        for d, c in zip(dates, closings[::4]):  # 종가만 가져오기 위해 slicing 사용\n",
        "            kospi_closings.append([d.text.strip(), float(c.text.replace(',', ''))])\n",
        "\n",
        "    return kospi_closings\n",
        "\n",
        "kospi_data = get_kospi_closing_prices()\n",
        "df = pd.DataFrame(kospi_data, columns=[\"Date\", \"Closing\"])\n",
        "\n",
        "# Shift를 사용해 다음 날짜의 종가를 가져와서 현재 날짜와 비교\n",
        "# 예: 10월 9일 종가보다 10월 10일 종가가 더 높다면 10월 9일 등락율 1이 됨\n",
        "\n",
        "df[\"Up/Down\"] = (df[\"Closing\"].shift(1) > df[\"Closing\"]).astype(int)\n",
        "\n",
        "# 날짜 기준으로 최근 30일의 데이터를 가져온 후, 정렬\n",
        "df = df.sort_values(by=\"Date\").tail(30).reset_index(drop=True)\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%Y.%m.%d').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "print(df)\n",
        "\n",
        "merged_df = pd.merge(news_df, df, left_on='date', right_on='Date', how='inner')\n",
        "merged_df = merged_df[['date', 'Up/Down', 'title', 'nouns']]\n",
        "print(merged_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe-vTxdr0yRi",
        "outputId": "86020655-c92d-47ca-a8eb-9b116b428c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'삼성': 0, '전자': 0, '다시': 0, '수요': 0, '균형': 0, '주택': 0, '공급': 0, '확대': 0, '정책': 0, '기대': 0, '구입': 0, '특례': 0, '보금자리': 0, '축소': 0, '파장': 0, '도생': 0, '오피스텔': 0, '기금': 0, '지원': 0, '부족': 0, '해소': 0, '도움': 0, '사라': 0, '버튼': 0, '알렉산더': 0, '맥퀸': 0, '후임': 0, '누가': 0, '리움': 0, '지갑': 0, '디폴트': 0, '옵션': 0, '완전': 0, '정복': 0, '당신': 0, '연금': 0, '부자': 0, '두산': 0, '로보틱스': 0, '상장': 0, '첫날': 0, '따블': 0, '에코': 0, '프로': 0, '내세': 0, '토방': 0, '시선': 0, '강탈': 0, '레드카펫': 0, '드레스': 0, '모두': 0, '백인': 0, '남성': 0, '명품': 0, '기업': 0, '케링': 0, '그룹': 0, '이유': 0, '빗썸': 0, '수수료': 0, '무료': 0, '프로젝트': 0, '덕분': 0, '단위': 0, '영업': 0, '복귀': 0, '강세': 0, '데스크': 0, '칼럼': 0, '먹거리': 0, '물가': 0, '기후': 0, '위기': 0, '욕구': 0, '폭발': 0, '뉴진스': 0, '팝업': 0, '스토어': 0, '대박': 0, '목욕탕': 0, '슬리퍼': 0, '회사': 0, '버켄스탁': 0, '당첨': 0, '중복': 0, '청약': 0, '거주': 0, '의무': 0, '마곡': 0, '하남': 0, '뉴홈': 0, '가구': 0, '매매': 0, '전세': 0, '이제': 0, '동행': 0, '고조': 0, '전쟁': 0, '우려': 0, '코인': 0, '정말': 0, '계획': 0, '최태원': 0, '구상': 0, '후계': 0, '구도': 0, '판매': 0, '쏘렌토': 0, '파업': 0, '리스크': 0, '변수': 0, '지방': 0, '소멸': 0, '해법': 0, '규제': 0, '패러다임': 0, '청계천': 0, '공장': 0, '땡큐': 0, '환호': 0, '포르셰': 0, '인천': 0, '뉴욕증시': 0, '예상': 0, '웃돈': 0, '국채': 0, '금리': 0, '상승': 0, '일제': 0, '하락': 0, '테슬라': 0, '한국': 0, '경쟁력': 0, '세계': 0, '하위': 0, '핵심': 0, '영역': 0, '린다': 0, '증시': 0, '채권': 0, '급등': 0, '코스피': 0, '부담': 0, '마감': 0, '엔씨소프트': 0, '카카오': 0, '국민': 0, '상주': 0, '투표': 0, '결과': 0, '인수': 0, '변신': 0, '좀처럼': 0, '고물': 0, '연내': 0, '추가': 0, '인상': 0, '분양': 0, '서울': 0, '미분': 0, '까닭': 0}\n",
            "삼성: 4\n",
            "전자: 4\n",
            "다시: 2\n",
            "수요: 1\n",
            "균형: 1\n",
            "주택: 3\n",
            "공급: 2\n",
            "확대: 1\n",
            "정책: 1\n",
            "기대: 1\n",
            "구입: 1\n",
            "특례: 1\n",
            "보금자리: 1\n",
            "축소: 1\n",
            "파장: 1\n",
            "도생: 1\n",
            "오피스텔: 1\n",
            "기금: 1\n",
            "지원: 1\n",
            "부족: 1\n",
            "해소: 1\n",
            "도움: 1\n",
            "사라: 1\n",
            "버튼: 1\n",
            "알렉산더: 1\n",
            "맥퀸: 1\n",
            "후임: 1\n",
            "누가: 1\n",
            "리움: 1\n",
            "지갑: 1\n",
            "디폴트: 1\n",
            "옵션: 1\n",
            "완전: 1\n",
            "정복: 1\n",
            "당신: 1\n",
            "연금: 1\n",
            "부자: 1\n",
            "두산: 2\n",
            "로보틱스: 2\n",
            "상장: 2\n",
            "첫날: 2\n",
            "따블: 2\n",
            "에코: 1\n",
            "프로: 1\n",
            "내세: 1\n",
            "토방: 1\n",
            "시선: 1\n",
            "강탈: 1\n",
            "레드카펫: 1\n",
            "드레스: 1\n",
            "모두: 3\n",
            "백인: 1\n",
            "남성: 1\n",
            "명품: 1\n",
            "기업: 1\n",
            "케링: 1\n",
            "그룹: 1\n",
            "이유: 3\n",
            "빗썸: 1\n",
            "수수료: 1\n",
            "무료: 1\n",
            "프로젝트: 1\n",
            "덕분: 1\n",
            "단위: 2\n",
            "영업: 4\n",
            "복귀: 2\n",
            "강세: 2\n",
            "데스크: 1\n",
            "칼럼: 1\n",
            "먹거리: 1\n",
            "물가: 1\n",
            "기후: 1\n",
            "위기: 2\n",
            "욕구: 1\n",
            "폭발: 1\n",
            "뉴진스: 1\n",
            "팝업: 1\n",
            "스토어: 1\n",
            "대박: 1\n",
            "목욕탕: 1\n",
            "슬리퍼: 1\n",
            "회사: 1\n",
            "버켄스탁: 1\n",
            "당첨: 1\n",
            "중복: 1\n",
            "청약: 1\n",
            "거주: 1\n",
            "의무: 1\n",
            "마곡: 1\n",
            "하남: 1\n",
            "뉴홈: 1\n",
            "가구: 1\n",
            "매매: 1\n",
            "전세: 1\n",
            "이제: 1\n",
            "동행: 1\n",
            "고조: 1\n",
            "전쟁: 1\n",
            "우려: 1\n",
            "코인: 1\n",
            "정말: 1\n",
            "계획: 2\n",
            "최태원: 2\n",
            "구상: 2\n",
            "후계: 2\n",
            "구도: 2\n",
            "판매: 1\n",
            "쏘렌토: 1\n",
            "파업: 1\n",
            "리스크: 1\n",
            "변수: 1\n",
            "지방: 1\n",
            "소멸: 1\n",
            "해법: 1\n",
            "규제: 1\n",
            "패러다임: 1\n",
            "청계천: 1\n",
            "공장: 1\n",
            "땡큐: 2\n",
            "환호: 2\n",
            "포르셰: 1\n",
            "인천: 1\n",
            "뉴욕증시: 1\n",
            "예상: 1\n",
            "웃돈: 1\n",
            "국채: 2\n",
            "금리: 3\n",
            "상승: 1\n",
            "일제: 1\n",
            "하락: 2\n",
            "테슬라: 1\n",
            "한국: 1\n",
            "경쟁력: 1\n",
            "세계: 1\n",
            "하위: 1\n",
            "핵심: 1\n",
            "영역: 1\n",
            "린다: 1\n",
            "증시: 1\n",
            "채권: 1\n",
            "급등: 1\n",
            "코스피: 1\n",
            "부담: 1\n",
            "마감: 1\n",
            "엔씨소프트: 1\n",
            "카카오: 1\n",
            "국민: 1\n",
            "상주: 1\n",
            "투표: 1\n",
            "결과: 1\n",
            "인수: 1\n",
            "변신: 1\n",
            "좀처럼: 1\n",
            "고물: 1\n",
            "연내: 1\n",
            "추가: 1\n",
            "인상: 1\n",
            "분양: 1\n",
            "서울: 1\n",
            "미분: 1\n",
            "까닭: 1\n"
          ]
        }
      ],
      "source": [
        "# 단어 점수 초기화 및 개수\n",
        "# 한 글자 제외 -> 두 글자 이상 단어\n",
        "\n",
        "# 'nouns' 칼럼의 값을 문자열로 변환\n",
        "df['nouns'] = merged_df['nouns'].astype(str)\n",
        "df = df.dropna(subset=['nouns'])\n",
        "\n",
        "# 'filtered_nouns' 컬럼 생성\n",
        "merged_df['filtered_nouns'] = merged_df['nouns'].apply(lambda x: [word for word in x.split(', ') if len(word) > 1])\n",
        "\n",
        "# 단어 점수 초기화\n",
        "word_scores = {word: 0 for word_list in merged_df['filtered_nouns'] for word in word_list}\n",
        "print(word_scores)\n",
        "\n",
        "# 단어 빈도수 계산\n",
        "from collections import Counter\n",
        "word_counts = Counter(word for word_list in merged_df['filtered_nouns'] for word in word_list)\n",
        "\n",
        "# 결과 출력\n",
        "for word, count in word_counts.items():\n",
        "    print(f\"{word}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QZ8ivkG096w",
        "outputId": "5ddbba72-dbcb-4a91-f7b6-9cf40495caee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of words: 198\n",
            "up : 75\n",
            "down : 123\n",
            "{'삼성': 2.484848484848485, '전자': 2.484848484848485, '다시': 1.2424242424242424, '수요': 0.6212121212121212, '균형': 0.6212121212121212, '주택': -0.13636363636363635, '공급': 0.24242424242424243, '확대': 0.6212121212121212, '정책': 0.6212121212121212, '기대': 0.6212121212121212, '구입': -0.3787878787878788, '특례': -0.3787878787878788, '보금자리': -0.3787878787878788, '축소': -0.3787878787878788, '파장': -0.3787878787878788, '도생': -0.3787878787878788, '오피스텔': -0.3787878787878788, '기금': -0.3787878787878788, '지원': -0.3787878787878788, '부족': -0.3787878787878788, '해소': -0.3787878787878788, '도움': -0.3787878787878788, '사라': -0.3787878787878788, '버튼': -0.3787878787878788, '알렉산더': -0.3787878787878788, '맥퀸': -0.3787878787878788, '후임': -0.3787878787878788, '누가': -0.3787878787878788, '리움': -0.3787878787878788, '지갑': -0.3787878787878788, '디폴트': -0.3787878787878788, '옵션': -0.3787878787878788, '완전': -0.3787878787878788, '정복': -0.3787878787878788, '당신': -0.3787878787878788, '연금': -0.3787878787878788, '부자': -0.3787878787878788, '두산': 1.2424242424242424, '로보틱스': 1.2424242424242424, '상장': 1.2424242424242424, '첫날': 1.2424242424242424, '따블': 1.2424242424242424, '에코': 0.6212121212121212, '프로': 0.6212121212121212, '내세': 0.6212121212121212, '토방': 0.6212121212121212, '시선': -0.3787878787878788, '강탈': -0.3787878787878788, '레드카펫': -0.3787878787878788, '드레스': -0.3787878787878788, '모두': -1.1363636363636362, '백인': -0.3787878787878788, '남성': -0.3787878787878788, '명품': -0.3787878787878788, '기업': -0.3787878787878788, '케링': -0.3787878787878788, '그룹': -0.3787878787878788, '이유': -0.13636363636363635, '빗썸': -0.3787878787878788, '수수료': -0.3787878787878788, '무료': -0.3787878787878788, '프로젝트': -0.3787878787878788, '덕분': -0.3787878787878788, '단위': 1.2424242424242424, '영업': 0.48484848484848486, '복귀': 1.2424242424242424, '강세': 1.2424242424242424, '데스크': 0.6212121212121212, '칼럼': 0.6212121212121212, '먹거리': 0.6212121212121212, '물가': 0.6212121212121212, '기후': 0.6212121212121212, '위기': 1.2424242424242424, '욕구': 0.6212121212121212, '폭발': 0.6212121212121212, '뉴진스': 0.6212121212121212, '팝업': 0.6212121212121212, '스토어': 0.6212121212121212, '대박': 0.6212121212121212, '목욕탕': 0.6212121212121212, '슬리퍼': 0.6212121212121212, '회사': 0.6212121212121212, '버켄스탁': 0.6212121212121212, '당첨': 0.6212121212121212, '중복': 0.6212121212121212, '청약': 0.6212121212121212, '거주': 0.6212121212121212, '의무': 0.6212121212121212, '마곡': 0.6212121212121212, '하남': 0.6212121212121212, '뉴홈': 0.6212121212121212, '가구': 0.6212121212121212, '매매': 0.6212121212121212, '전세': 0.6212121212121212, '이제': 0.6212121212121212, '동행': 0.6212121212121212, '고조': 0.6212121212121212, '전쟁': 0.6212121212121212, '우려': 0.6212121212121212, '코인': 0.6212121212121212, '정말': 0.6212121212121212, '계획': -0.7575757575757576, '최태원': -0.7575757575757576, '구상': -0.7575757575757576, '후계': -0.7575757575757576, '구도': -0.7575757575757576, '판매': -0.3787878787878788, '쏘렌토': -0.3787878787878788, '파업': -0.3787878787878788, '리스크': -0.3787878787878788, '변수': -0.3787878787878788, '지방': -0.3787878787878788, '소멸': -0.3787878787878788, '해법': -0.3787878787878788, '규제': -0.3787878787878788, '패러다임': -0.3787878787878788, '청계천': -0.3787878787878788, '공장': -0.3787878787878788, '땡큐': -0.7575757575757576, '환호': -0.7575757575757576, '포르셰': -0.3787878787878788, '인천': -0.3787878787878788, '뉴욕증시': -0.3787878787878788, '예상': -0.3787878787878788, '웃돈': -0.3787878787878788, '국채': -0.7575757575757576, '금리': -1.1363636363636362, '상승': -0.3787878787878788, '일제': -0.3787878787878788, '하락': -0.7575757575757576, '테슬라': -0.3787878787878788, '한국': -0.3787878787878788, '경쟁력': -0.3787878787878788, '세계': -0.3787878787878788, '하위': -0.3787878787878788, '핵심': -0.3787878787878788, '영역': -0.3787878787878788, '린다': -0.3787878787878788, '증시': -0.3787878787878788, '채권': -0.3787878787878788, '급등': -0.3787878787878788, '코스피': -0.3787878787878788, '부담': -0.3787878787878788, '마감': -0.3787878787878788, '엔씨소프트': -0.3787878787878788, '카카오': -0.3787878787878788, '국민': -0.3787878787878788, '상주': -0.3787878787878788, '투표': -0.3787878787878788, '결과': -0.3787878787878788, '인수': -0.3787878787878788, '변신': -0.3787878787878788, '좀처럼': -0.3787878787878788, '고물': -0.3787878787878788, '연내': -0.3787878787878788, '추가': -0.3787878787878788, '인상': -0.3787878787878788, '분양': -0.3787878787878788, '서울': -0.3787878787878788, '미분': -0.3787878787878788, '까닭': -0.3787878787878788}\n"
          ]
        }
      ],
      "source": [
        "# 단어 점수 부여\n",
        "\n",
        "# 전체 단어 개수 출력\n",
        "total_words = sum(word_counts.values())\n",
        "print(f\"\\nTotal number of words: {total_words}\")\n",
        "\n",
        "# Up/Down 값이 1인 데이터에서 포함된 단어의 리스트\n",
        "up = []\n",
        "for nouns in merged_df[merged_df['Up/Down'] == 1]['filtered_nouns']:\n",
        "    up.extend(nouns)\n",
        "\n",
        "# Up/Down 값이 0인 데이터에서 포함된 단어의 리스트\n",
        "down = []\n",
        "for nouns in merged_df[merged_df['Up/Down'] == 0]['filtered_nouns']:\n",
        "    down.extend(nouns)\n",
        "\n",
        "print(\"up :\", len(up))\n",
        "print(\"down :\", len(down))\n",
        "\n",
        "# 상승 비율과 하락 비율 계산\n",
        "total_words = len(up) + len(down)\n",
        "up_ratio = len(up) / total_words\n",
        "down_ratio = len(down) / total_words\n",
        "\n",
        "# 단어 점수 초기화\n",
        "word_scores = {word: 0 for word in word_scores.keys()}  # 기존의 word_scores 딕셔너리 사용\n",
        "\n",
        "# Up(1) 데이터의 단어들에 대해서 하락 비율을 더해주기\n",
        "for word in up:\n",
        "    if word in word_scores:\n",
        "        word_scores[word] += down_ratio\n",
        "\n",
        "# Down(0) 데이터의 단어들에 대해서 상승 비율을 차감해주기\n",
        "for word in down:\n",
        "    if word in word_scores:\n",
        "        word_scores[word] -= up_ratio\n",
        "\n",
        "# 결과 확인\n",
        "print(word_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqxqymCI2F5A",
        "outputId": "d41db634-1acc-47c7-cbe5-dcda71c7dfc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "감성 사전 평균 점수 :  -8.61974398000898e-17\n",
            "          date  Up/Down  sent_score  sent_label  \\\n",
            "0   2023-09-19        1    2.070707           1   \n",
            "1   2023-09-19        1    2.070707           1   \n",
            "2   2023-09-19        1    0.458874           1   \n",
            "3   2023-09-20        0   -0.338384           0   \n",
            "4   2023-09-27        0   -0.301136           0   \n",
            "5   2023-09-27        0   -0.378788           0   \n",
            "6   2023-09-27        0   -0.378788           0   \n",
            "7   2023-10-04        0   -0.378788           0   \n",
            "8   2023-10-05        1    1.242424           1   \n",
            "9   2023-10-05        1    0.621212           1   \n",
            "10  2023-10-05        1    1.242424           1   \n",
            "11  2023-10-06        0   -0.378788           0   \n",
            "12  2023-10-06        0   -0.443182           0   \n",
            "13  2023-10-06        0   -0.378788           0   \n",
            "14  2023-10-11        1    1.530303           1   \n",
            "15  2023-10-11        1    1.530303           1   \n",
            "16  2023-10-11        1    0.724747           1   \n",
            "17  2023-10-11        1    0.512987           1   \n",
            "18  2023-10-11        1    0.621212           1   \n",
            "19  2023-10-11        1    0.621212           1   \n",
            "20  2023-10-11        1    0.621212           1   \n",
            "21  2023-10-11        1    0.621212           1   \n",
            "22  2023-10-11        1    0.724747           1   \n",
            "23  2023-10-12        0   -0.757576           0   \n",
            "24  2023-10-12        0   -0.757576           0   \n",
            "25  2023-10-12        0   -0.378788           0   \n",
            "26  2023-10-12        0   -0.338384           0   \n",
            "27  2023-10-12        0   -0.297980           0   \n",
            "28  2023-10-13        0   -0.541667           0   \n",
            "29  2023-10-13        0   -0.378788           0   \n",
            "30  2023-10-13        0   -0.547138           0   \n",
            "31  2023-10-13        0   -0.541667           0   \n",
            "32  2023-10-13        0   -0.378788           0   \n",
            "33  2023-10-13        0   -0.568182           0   \n",
            "34  2023-10-13        0   -0.473485           0   \n",
            "35  2023-10-13        0   -0.378788           0   \n",
            "36  2023-10-13        0   -0.378788           0   \n",
            "37  2023-10-13        0   -0.505051           0   \n",
            "38  2023-10-13        0   -0.378788           0   \n",
            "\n",
            "                                       title  \\\n",
            "0                      삼성전자, 3주만에 다시 '6만전자'로   \n",
            "1                      삼성전자, 3주만에 다시 '6만전자'로   \n",
            "2                   수요와 균형 이루는 주택공급 확대 정책 기대   \n",
            "3              주택구입자 3분의1이 받은 특례보금자리론…축소 파장은   \n",
            "4                도생·오피스텔에 기금 지원…공급부족 해소 도움될까   \n",
            "5                사라 버튼 떠나는 알렉산더 맥퀸, 후임 누가 될까   \n",
            "6                         이더리움 NFT가 지갑이 된다고?   \n",
            "7                    디폴트옵션 완전정복…당신도 연금부자 됩니다   \n",
            "8                  IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "9           \"에코프로 욕하려면 80만원 내세요\"…확 달라진 '종토방'   \n",
            "10                 IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "11               80~1000만원대까지…시선강탈 레드카펫 ★드레스   \n",
            "12           \"모두 백인 남성이네\" 명품기업 케링그룹, 욕 먹는 이유   \n",
            "13                빗썸 수수료 무료, 830 프로젝트 덕분이라고?   \n",
            "14               삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "15               삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "16                       [데스크칼럼]먹거리 물가와 기후위기   \n",
            "17        \"억눌렸던 욕구 폭발\"…뉴진스 '팝업스토어' 대박 이유 있었다   \n",
            "18         '목욕탕 슬리퍼'가 11조원 회사로…200년을 버틴 버켄스탁   \n",
            "19           뉴:홈, 당첨일 다르면 중복청약 OK…거주 의무도 꼼꼼히   \n",
            "20              마곡 3억·하남 4억대 ‘뉴홈’ 3300가구 풀린다   \n",
            "21                 같이 오르내리던 매매·전세가, 이제 동행 끝?   \n",
            "22           고조되는 이-팔 전쟁 우려, 코인은 정말 위기에 강한가?   \n",
            "23             \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "24             \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "25         \"클수록 좋다\" SUV 판매 1위는 쏘렌토…파업 리스크 변수   \n",
            "26              지방소멸 해법 떠오른 다주택자 규제…패러다임 바뀌나   \n",
            "27            청계천 떠난 '작은 공장'이 말하는 떠나야만 했던 이유   \n",
            "28     \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "29                     포르셰 뽑은 30대, 인천서 확 늘었다   \n",
            "30  뉴욕증시, 예상 웃돈 CPI·국채금리 상승에 일제 하락…테슬라 1.5%↓   \n",
            "31     \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "32            한국 AI 경쟁력 세계 6위?…하위 굳히는 핵심 영역은   \n",
            "33               '미 국채가 안 팔린다'…증시 흔든 채권금리 급등   \n",
            "34           코스피, 美 CPI 부담에 1% 하락…2456.15 마감   \n",
            "35         '엔씨소프트 vs 카카오' 국민 밉상주 투표 열렸다…결과는?   \n",
            "36             550억에 인수하더니…'마흔살' KFC의 놀라운 변신   \n",
            "37            좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "38                  분양가 너무 비쌌나…서울서 미분양 나온 까닭   \n",
            "\n",
            "                                    nouns  \n",
            "0                        삼성, 전자, 주, 다시, 로  \n",
            "1                        삼성, 전자, 주, 다시, 로  \n",
            "2              수요, 균형, 주택, 공급, 확대, 정책, 기대  \n",
            "3          주택, 구입, 이, 특례, 보금자리, 론, 축소, 파장  \n",
            "4        도생, 오피스텔, 기금, 지원, 공급, 부족, 해소, 도움  \n",
            "5                사라, 버튼, 알렉산더, 맥퀸, 후임, 누가  \n",
            "6                               더, 리움, 지갑  \n",
            "7             디폴트, 옵션, 완전, 정복, 당신, 연금, 부자  \n",
            "8                    두산, 로보틱스, 상장, 첫날, 따블  \n",
            "9                 에코, 프로, 욕, 내세, 확, 종, 토방  \n",
            "10                   두산, 로보틱스, 상장, 첫날, 따블  \n",
            "11                      시선, 강탈, 레드카펫, 드레스  \n",
            "12      모두, 백인, 남성, 명품, 기업, 케링, 그룹, 욕, 이유  \n",
            "13                  빗썸, 수수료, 무료, 프로젝트, 덕분  \n",
            "14           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "15           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "16               데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "17           욕구, 폭발, 뉴진스, 팝업, 스토어, 대박, 이유  \n",
            "18                     목욕탕, 슬리퍼, 회사, 버켄스탁  \n",
            "19            뉴, 홈, 당첨, 일, 중복, 청약, 거주, 의무  \n",
            "20                         마곡, 하남, 뉴홈, 가구  \n",
            "21                      매매, 전세, 이제, 동행, 끝  \n",
            "22           고조, 이, 팔, 전쟁, 우려, 코인, 정말, 위기  \n",
            "23                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "24                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "25                판매, 위, 쏘렌토, 파업, 리스크, 변수  \n",
            "26               지방, 소멸, 해법, 주택, 규제, 패러다임  \n",
            "27                      청계천, 공장, 이, 말, 이유  \n",
            "28          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "29                             포르셰, 인천, 확  \n",
            "30  뉴욕증시, 예상, 웃돈, 국채, 금리, 상승, 일제, 하락, 테슬라  \n",
            "31          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "32             한국, 경쟁력, 세계, 위, 하위, 핵심, 영역  \n",
            "33              국채, 안, 린다, 증시, 채권, 금리, 급등  \n",
            "34                        코스피, 부담, 하락, 마감  \n",
            "35             엔씨소프트, 카카오, 국민, 상주, 투표, 결과  \n",
            "36                           인수, 살, 의, 변신  \n",
            "37             좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "38                         분양, 서울, 미분, 까닭  \n"
          ]
        }
      ],
      "source": [
        "# 감성 사전 완료\n",
        "\n",
        "total = []\n",
        "for nouns in merged_df['filtered_nouns']:\n",
        "    sent_score = 0\n",
        "    for noun in nouns:\n",
        "        if noun in word_scores:\n",
        "            sent_score += word_scores[noun]\n",
        "\n",
        "    # 해당 뉴스 제목에 포함된 단어의 수로 나누어 평균 점수를 계산\n",
        "    avg_sent_score = sent_score / len(nouns) if nouns else 0  # 단어가 없는 경우 0으로 처리\n",
        "    total.append(avg_sent_score)\n",
        "\n",
        "merged_df['sent_score'] = total\n",
        "\n",
        "# 감성사전의 평균 점수 계산\n",
        "\n",
        "sent_mean = sum(word_scores.values()) / len(word_scores)\n",
        "print('감성 사전 평균 점수 : ',sent_mean)\n",
        "\n",
        "# 감성 점수 계산\n",
        "def calculate_sentiment_score(noun_list):\n",
        "    score = 0\n",
        "    for noun in noun_list:\n",
        "        if noun in word_scores:\n",
        "            score += word_scores[noun]\n",
        "    return score / (len(noun_list) if len(noun_list) != 0 else 1)\n",
        "\n",
        "merged_df['sent_score'] = merged_df['filtered_nouns'].apply(calculate_sentiment_score)\n",
        "\n",
        "# 평균 점수를 기준으로 라벨링\n",
        "merged_df['sent_label'] = merged_df['sent_score'].apply(lambda x: 1 if x > sent_mean else 0)\n",
        "\n",
        "\n",
        "\n",
        "result_df = merged_df[['date', 'Up/Down', 'sent_score', 'sent_label', 'title', 'nouns']]\n",
        "print(result_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRO0d5yn2mjQ",
        "outputId": "87de05c8-c2bd-466a-8cce-7daebbc4e482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.4194\n",
            "Epoch 1: val_acc improved from -inf to 1.00000, saving model to best_model.h5\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.6937 - acc: 0.4194 - val_loss: 0.6604 - val_acc: 1.0000\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6911 - acc: 0.5161\n",
            "Epoch 2: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6911 - acc: 0.5161 - val_loss: 0.6604 - val_acc: 1.0000\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6893 - acc: 0.5161\n",
            "Epoch 3: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6893 - acc: 0.5161 - val_loss: 0.6599 - val_acc: 1.0000\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6874 - acc: 0.5161\n",
            "Epoch 4: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.6874 - acc: 0.5161 - val_loss: 0.6594 - val_acc: 1.0000\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6853 - acc: 0.5161\n",
            "Epoch 5: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.6853 - acc: 0.5161 - val_loss: 0.6589 - val_acc: 1.0000\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6829 - acc: 0.5161\n",
            "Epoch 6: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.6829 - acc: 0.5161 - val_loss: 0.6584 - val_acc: 1.0000\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6802 - acc: 0.5161\n",
            "Epoch 7: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.6802 - acc: 0.5161 - val_loss: 0.6578 - val_acc: 1.0000\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6769 - acc: 0.5161\n",
            "Epoch 8: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6769 - acc: 0.5161 - val_loss: 0.6571 - val_acc: 1.0000\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6731 - acc: 0.5806\n",
            "Epoch 9: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6731 - acc: 0.5806 - val_loss: 0.6563 - val_acc: 1.0000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6685 - acc: 0.7419\n",
            "Epoch 10: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6685 - acc: 0.7419 - val_loss: 0.6555 - val_acc: 1.0000\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6630 - acc: 0.8065\n",
            "Epoch 11: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.6630 - acc: 0.8065 - val_loss: 0.6545 - val_acc: 1.0000\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6563 - acc: 0.8710\n",
            "Epoch 12: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6563 - acc: 0.8710 - val_loss: 0.6535 - val_acc: 1.0000\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6483 - acc: 0.9032\n",
            "Epoch 13: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6483 - acc: 0.9032 - val_loss: 0.6523 - val_acc: 1.0000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6387 - acc: 0.9355\n",
            "Epoch 14: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6387 - acc: 0.9355 - val_loss: 0.6508 - val_acc: 1.0000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6270 - acc: 0.9355\n",
            "Epoch 15: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.6270 - acc: 0.9355 - val_loss: 0.6489 - val_acc: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# 모델링\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. 데이터 준비\n",
        "X_data = merged_df['nouns'].apply(lambda x: ' '.join([word for word in x.split(', ') if len(word) > 1])).values\n",
        "Y_data = merged_df['sent_label'].values  # 기존의 'merged_df'를 사용\n",
        "\n",
        "# 2. 토큰화 및 패딩\n",
        "vocab_size = 2000\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(X_data)\n",
        "X_tokenized = tokenizer.texts_to_sequences(X_data)\n",
        "X_padded = pad_sequences(X_tokenized, maxlen=30)\n",
        "\n",
        "# 3. Bi-LSTM 모델 구축 및 훈련\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_padded, Y_data, epochs=15, callbacks=[es, mc], batch_size=256, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk8lboFM2vfR",
        "outputId": "fdad5ec3-0e50-4702-966a-b83fb87243e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 19ms/step\n",
            "미래 주식 시장은 부정적으로 움직일 것으로 예상됩니다.\n",
            "긍정적 뉴스 수: 21 (20.19%)\n",
            "부정적 뉴스 수: 83 (79.81%)\n",
            "\n",
            "긍정적 뉴스 예시:\n",
            "- 뉴:홈, 당첨일 다르면 중복청약 OK…거주 의무도 꼼꼼히\n",
            "- 마곡 3억·하남 4억대 ‘뉴홈’ 3300가구 풀린다\n",
            "- 청약 경쟁률 수십대 1인데…왜 '완판'은 안될까?\n",
            "- 삼성전자,한 달 만에 ‘7만전자’복귀\n",
            "- 삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세\n",
            "\n",
            "부정적 뉴스 예시:\n",
            "- 만기가 돌아왔다…갈아타기 고민하는 예테크족\n",
            "- 디폴트옵션 완전정복…당신도 연금부자 됩니다\n",
            "- \"차량 3대면 주차비 20만원 내세요\" 주차난에 차등 요금 도입 단지↑\n",
            "- 치솟는 강남권 초소형 아파트 인기… 일부 단지 신고가 근접\n",
            "- “MZ는 주택시장 풍향계?”…서울집 내다 파는 2030 늘고, 영끌족 줄어\n"
          ]
        }
      ],
      "source": [
        "# 최신 뉴스 크롤링 후 모델에 적용해서 최종 결과 확인\n",
        "\n",
        "# 뉴스 제목 크롤링\n",
        "base_url = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101&date=\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "start_date = datetime.datetime.now() - datetime.timedelta(days=30)\n",
        "end_date = datetime.datetime.now() - datetime.timedelta(days=5)\n",
        "current_date = start_date\n",
        "\n",
        "news_data = []\n",
        "\n",
        "while current_date <= end_date:\n",
        "    response = requests.get(base_url + current_date.strftime('%Y%m%d'), headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    for item in soup.select(\".cluster_text a\"):\n",
        "        title = item.text.strip()\n",
        "        news_data.append({\n",
        "            'date': current_date.strftime('%Y-%m-%d'),\n",
        "            'title': title\n",
        "        })\n",
        "    current_date += datetime.timedelta(days=1)\n",
        "\n",
        "news_df = pd.DataFrame(news_data, columns=['date', 'title'])\n",
        "\n",
        "# 명사 추출\n",
        "okt = Okt()\n",
        "news_df['nouns'] = news_df['title'].apply(lambda x: ', '.join(okt.nouns(x)))\n",
        "\n",
        "# 감성 사전과 비교하여 감성 점수 계산\n",
        "news_df['filtered_nouns'] = news_df['nouns'].apply(lambda x: [word for word in x.split(', ') if len(word) > 1])\n",
        "news_df['sent_score'] = news_df['filtered_nouns'].apply(calculate_sentiment_score)  # 이전에 정의한 함수\n",
        "\n",
        "# 예측을 위한 데이터 전처리\n",
        "X_test_tokenized = tokenizer.texts_to_sequences(news_df['nouns'].apply(lambda x: ' '.join([word for word in x.split(', ') if len(word) > 1])).values)\n",
        "X_test_padded = pad_sequences(X_test_tokenized, maxlen=30)\n",
        "\n",
        "# 훈련된 Bi-LSTM 모델로 예측\n",
        "predicted = model.predict(X_test_padded)\n",
        "news_df['predicted_label'] = (predicted > 0.5).astype(int)\n",
        "\n",
        "# 결과 출력\n",
        "positive_news_ratio = news_df['predicted_label'].sum() / len(news_df)\n",
        "if positive_news_ratio > 0.5:\n",
        "    print(\"미래 주식 시장은 긍정적으로 움직일 것으로 예상됩니다.\")\n",
        "else:\n",
        "    print(\"미래 주식 시장은 부정적으로 움직일 것으로 예상됩니다.\")\n",
        "\n",
        "    # 각 뉴스의 감성 점수를 바탕으로 긍정적 및 부정적 뉴스 개수 확인 및 출력\n",
        "sent_mean = news_df['sent_score'].mean()\n",
        "\n",
        "pos_news = len(news_df[news_df['sent_score'] > sent_mean])\n",
        "neg_news = len(news_df[news_df['sent_score'] <= sent_mean])\n",
        "total_news = len(news_df)\n",
        "\n",
        "print(f\"긍정적 뉴스 수: {pos_news} ({pos_news/total_news*100:.2f}%)\")\n",
        "print(f\"부정적 뉴스 수: {neg_news} ({neg_news/total_news*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n긍정적 뉴스 예시:\")\n",
        "for title in news_df[news_df['sent_score'] > sent_mean]['title'].head(5):\n",
        "    print(\"-\", title)\n",
        "\n",
        "print(\"\\n부정적 뉴스 예시:\")\n",
        "for title in news_df[news_df['sent_score'] <= sent_mean]['title'].head(5):\n",
        "    print(\"-\", title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGp5NA9F4_Q6",
        "outputId": "4ead13c7-7f3e-4ed5-b39b-8b7aab0782fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "          date                                              title  \\\n",
            "8   2023-09-18                  테슬라 270달러 넘자 매물 폭탄…애플-엔비디아는 저가 매수   \n",
            "9   2023-09-19                   오염수 2차 방류 앞두고 런던협약‧해양재판소 급부상, 왜?   \n",
            "10  2023-09-19                   오염수 2차 방류 앞두고 런던협약‧해양재판소 급부상, 왜?   \n",
            "11  2023-09-21                           고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "12  2023-09-21                           고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "13  2023-09-21                           고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "14  2023-09-25                  3억불 베팅했는데 사는 종목마다 하락…마이너스의 손 언제까지   \n",
            "15  2023-09-27                                 SKT가 AI에 사활 건 이유는?   \n",
            "16  2023-09-27                                 SKT가 AI에 사활 건 이유는?   \n",
            "17  2023-09-27                                 SKT가 AI에 사활 건 이유는?   \n",
            "18  2023-09-28                                  높은 자리에 있다고 진짜 리더랴   \n",
            "19  2023-10-01                            그들은 지금 백성을 위한 길을 걷고 있는가   \n",
            "20  2023-10-01                          당신의 건보료 동결, 누구의 희생 덕분일까요?   \n",
            "21  2023-10-03                        [데스크칼럼]반쪽 주택대책 안되려면 ‘실행’뿐이다   \n",
            "22  2023-10-03                        [데스크칼럼]반쪽 주택대책 안되려면 ‘실행’뿐이다   \n",
            "23  2023-10-03                     공언이 공수표로…스스로 어긴 재정준칙, 설득력 있을까?   \n",
            "24  2023-10-05                         KISCO홀딩스 '리레이팅'과 거버넌스의 중요성   \n",
            "25  2023-10-07                        주력 저축銀 부진에…웰컴, '군살빼기' 모드 전환   \n",
            "26  2023-10-09                 질병청 vs 담배업계, 전자담배 ‘미세먼지’ 논란 재점화…왜?   \n",
            "27  2023-10-09                 질병청 vs 담배업계, 전자담배 ‘미세먼지’ 논란 재점화…왜?   \n",
            "28  2023-10-09                                 도망친 권력자 대신 나라를 구하다   \n",
            "29  2023-10-09                    반도체에서 큰 손실…이젠 테슬라·나스닥100 상승에 베팅   \n",
            "30  2023-10-09                 질병청 vs 담배업계, 전자담배 ‘미세먼지’ 논란 재점화…왜?   \n",
            "31  2023-10-09                   화장실 갈 때도 눈치 보는 콜센터 상담사의 비명 [視리즈]   \n",
            "32  2023-10-10                    '알맹이' 없었던 런던총회…'신냉전 구도' 오염수 공방전   \n",
            "33  2023-10-10   누적 스트리밍 5001억회… 전 세계인 63번씩 이용한 꼴 [연중기획-K브랜드 리포트]   \n",
            "34  2023-10-10  ‘TOP 100’ 차트서 인디공연까지… 한국 음악산업 이끈다 [연중기획-K브랜드 리포트]   \n",
            "35  2023-10-10                    '알맹이' 없었던 런던총회…'신냉전 구도' 오염수 공방전   \n",
            "36  2023-10-10                 CPA 불합격 수험생 293명 행정심판 제기…\"신뢰이익 침해\"   \n",
            "37  2023-10-11                      비둘기로 변한 연준?…국채 금리 안정에도 남은 리스크   \n",
            "38  2023-10-11                                [데스크칼럼]먹거리 물가와 기후위기   \n",
            "39  2023-10-11                                [데스크칼럼]먹거리 물가와 기후위기   \n",
            "40  2023-10-12                     40년 금리 패러다임 끝났다…주식 줄이고 채권 늘릴 때   \n",
            "41  2023-10-12                      '오이밭'된 왓챠, LG U+는 '신발끈'만 묶었을까   \n",
            "42  2023-10-12                  민주당 진교훈 강서구청장 당선…뉴욕증시, 국채금리 하락에 ↑   \n",
            "43  2023-10-13                     침체 없이는 2% 인플레 불가능?…증시에 적이 된 거시   \n",
            "44  2023-10-13                     좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "45  2023-10-13              서프라이즈 美 물가에 살아난 긴축 우려…환율 1350원대 안착 시도   \n",
            "46  2023-10-13                          장기물 국채경매 부진…국채금리 다시 꼬리 든다   \n",
            "47  2023-10-13                         꽃이 된 한글 훈민정花의 美친 세계화 [소셜+]   \n",
            "48  2023-10-13               뉴욕증시, 9월 물가보고서 영향 하락…출근길, 짙은 안개 '조심'   \n",
            "\n",
            "                                          nouns  \n",
            "8                 테슬라, 매물, 폭탄, 애플, 엔비디아, 저가, 매수  \n",
            "9            오염수, 차, 방류, 런던, 협약, 해양, 재판소, 급부, 왜  \n",
            "10           오염수, 차, 방류, 런던, 협약, 해양, 재판소, 급부, 왜  \n",
            "11                   고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "12                   고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "13                   고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "14                      베팅, 종목, 하락, 마이너스, 손, 언제  \n",
            "15                                    사활, 건, 이유  \n",
            "16                                    사활, 건, 이유  \n",
            "17                                    사활, 건, 이유  \n",
            "18                                    자리, 진짜, 리  \n",
            "19                              그, 지금, 백성, 위, 길  \n",
            "20                 당신, 건, 보료, 동결, 누구, 희생, 덕분, 요  \n",
            "21                   데스크, 칼럼, 반쪽, 주택, 대책, 실행, 뿐  \n",
            "22                   데스크, 칼럼, 반쪽, 주택, 대책, 실행, 뿐  \n",
            "23                     공언, 수표로, 스스로, 재정, 준칙, 설득  \n",
            "24                  홀딩스, 리, 레이, 팅, 과, 거버넌스, 중요성  \n",
            "25               주력, 저축, 부진, 웰컴, 군살, 빼기, 모드, 전환  \n",
            "26      질병, 청, 담배, 업계, 전자담배, 미세먼지, 논란, 재, 점화, 왜  \n",
            "27      질병, 청, 담배, 업계, 전자담배, 미세먼지, 논란, 재, 점화, 왜  \n",
            "28                               권력자, 대신, 나라, 구  \n",
            "29                 반도체, 손실, 젠, 테슬라, 나스닥, 상승, 베팅  \n",
            "30      질병, 청, 담배, 업계, 전자담배, 미세먼지, 논란, 재, 점화, 왜  \n",
            "31                 화장실, 때, 눈치, 콜센터, 상담사, 비명, 리즈  \n",
            "32                알맹이, 런던, 총회, 냉전, 구도, 오염수, 공방전  \n",
            "33  누적, 스트리밍, 전, 세계, 번, 이용, 꼴, 연중, 기획, 브랜드, 리포트  \n",
            "34         차트, 공연, 한국, 음악, 산업, 연중, 기획, 브랜드, 리포트  \n",
            "35                알맹이, 런던, 총회, 냉전, 구도, 오염수, 공방전  \n",
            "36              불합격, 수험생, 명, 행정심판, 제기, 신뢰이익, 침해  \n",
            "37                      비둘기, 준, 국채, 금리, 안정, 리스크  \n",
            "38                     데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "39                     데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "40                       금리, 패러다임, 주식, 줄, 채권, 때  \n",
            "41                             오이, 밭, 왓챠, 발끈, 만  \n",
            "42    민주당, 진, 교훈, 강서구, 청장, 당선, 뉴욕증시, 국채, 금리, 하락  \n",
            "43                      침체, 인플레, 불가능, 증시, 적, 거시  \n",
            "44                   좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "45                서프라이즈, 물가, 긴축, 우려, 환율, 안착, 시도  \n",
            "46            장기, 물, 국채, 경매, 부진, 국채, 금리, 다시, 꼬리  \n",
            "47                   꽃, 한글, 훈, 민정, 의, 친, 세계, 소셜  \n",
            "48           뉴욕증시, 물가, 보고서, 영향, 하락, 출근길, 안개, 조심  \n",
            "          Date  Closing  Up/Down\n",
            "0   2023-08-31  2556.27        1\n",
            "1   2023-09-01  2563.71        1\n",
            "2   2023-09-04  2584.55        0\n",
            "3   2023-09-05  2582.18        0\n",
            "4   2023-09-06  2563.34        0\n",
            "5   2023-09-07  2548.26        0\n",
            "6   2023-09-08  2547.68        1\n",
            "7   2023-09-11  2556.88        0\n",
            "8   2023-09-12  2536.58        0\n",
            "9   2023-09-13  2534.70        1\n",
            "10  2023-09-14  2572.89        1\n",
            "11  2023-09-15  2601.28        0\n",
            "12  2023-09-18  2574.72        0\n",
            "13  2023-09-19  2559.21        1\n",
            "14  2023-09-20  2559.74        0\n",
            "15  2023-09-21  2514.97        0\n",
            "16  2023-09-22  2508.13        0\n",
            "17  2023-09-25  2495.76        0\n",
            "18  2023-09-26  2462.97        1\n",
            "19  2023-09-27  2465.07        0\n",
            "20  2023-10-04  2405.69        0\n",
            "21  2023-10-05  2403.60        1\n",
            "22  2023-10-06  2408.73        0\n",
            "23  2023-10-10  2402.58        1\n",
            "24  2023-10-11  2450.08        1\n",
            "25  2023-10-12  2479.82        0\n",
            "26  2023-10-13  2456.15        0\n",
            "27  2023-10-16  2436.24        1\n",
            "28  2023-10-17  2460.17        1\n",
            "29  2023-10-18  2462.60        0\n",
            "          date  Up/Down                                              title  \\\n",
            "0   2023-09-18        0                  테슬라 270달러 넘자 매물 폭탄…애플-엔비디아는 저가 매수   \n",
            "1   2023-09-19        1                   오염수 2차 방류 앞두고 런던협약‧해양재판소 급부상, 왜?   \n",
            "2   2023-09-19        1                   오염수 2차 방류 앞두고 런던협약‧해양재판소 급부상, 왜?   \n",
            "3   2023-09-21        0                           고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "4   2023-09-21        0                           고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "5   2023-09-21        0                           고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "6   2023-09-25        0                  3억불 베팅했는데 사는 종목마다 하락…마이너스의 손 언제까지   \n",
            "7   2023-09-27        0                                 SKT가 AI에 사활 건 이유는?   \n",
            "8   2023-09-27        0                                 SKT가 AI에 사활 건 이유는?   \n",
            "9   2023-09-27        0                                 SKT가 AI에 사활 건 이유는?   \n",
            "10  2023-10-05        1                         KISCO홀딩스 '리레이팅'과 거버넌스의 중요성   \n",
            "11  2023-10-10        1                    '알맹이' 없었던 런던총회…'신냉전 구도' 오염수 공방전   \n",
            "12  2023-10-10        1   누적 스트리밍 5001억회… 전 세계인 63번씩 이용한 꼴 [연중기획-K브랜드 리포트]   \n",
            "13  2023-10-10        1  ‘TOP 100’ 차트서 인디공연까지… 한국 음악산업 이끈다 [연중기획-K브랜드 리포트]   \n",
            "14  2023-10-10        1                    '알맹이' 없었던 런던총회…'신냉전 구도' 오염수 공방전   \n",
            "15  2023-10-10        1                 CPA 불합격 수험생 293명 행정심판 제기…\"신뢰이익 침해\"   \n",
            "16  2023-10-11        1                      비둘기로 변한 연준?…국채 금리 안정에도 남은 리스크   \n",
            "17  2023-10-11        1                                [데스크칼럼]먹거리 물가와 기후위기   \n",
            "18  2023-10-11        1                                [데스크칼럼]먹거리 물가와 기후위기   \n",
            "19  2023-10-12        0                     40년 금리 패러다임 끝났다…주식 줄이고 채권 늘릴 때   \n",
            "20  2023-10-12        0                      '오이밭'된 왓챠, LG U+는 '신발끈'만 묶었을까   \n",
            "21  2023-10-12        0                  민주당 진교훈 강서구청장 당선…뉴욕증시, 국채금리 하락에 ↑   \n",
            "22  2023-10-13        0                     침체 없이는 2% 인플레 불가능?…증시에 적이 된 거시   \n",
            "23  2023-10-13        0                     좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "24  2023-10-13        0              서프라이즈 美 물가에 살아난 긴축 우려…환율 1350원대 안착 시도   \n",
            "25  2023-10-13        0                          장기물 국채경매 부진…국채금리 다시 꼬리 든다   \n",
            "26  2023-10-13        0                         꽃이 된 한글 훈민정花의 美친 세계화 [소셜+]   \n",
            "27  2023-10-13        0               뉴욕증시, 9월 물가보고서 영향 하락…출근길, 짙은 안개 '조심'   \n",
            "\n",
            "                                          nouns  \n",
            "0                 테슬라, 매물, 폭탄, 애플, 엔비디아, 저가, 매수  \n",
            "1            오염수, 차, 방류, 런던, 협약, 해양, 재판소, 급부, 왜  \n",
            "2            오염수, 차, 방류, 런던, 협약, 해양, 재판소, 급부, 왜  \n",
            "3                    고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "4                    고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "5                    고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "6                       베팅, 종목, 하락, 마이너스, 손, 언제  \n",
            "7                                     사활, 건, 이유  \n",
            "8                                     사활, 건, 이유  \n",
            "9                                     사활, 건, 이유  \n",
            "10                  홀딩스, 리, 레이, 팅, 과, 거버넌스, 중요성  \n",
            "11                알맹이, 런던, 총회, 냉전, 구도, 오염수, 공방전  \n",
            "12  누적, 스트리밍, 전, 세계, 번, 이용, 꼴, 연중, 기획, 브랜드, 리포트  \n",
            "13         차트, 공연, 한국, 음악, 산업, 연중, 기획, 브랜드, 리포트  \n",
            "14                알맹이, 런던, 총회, 냉전, 구도, 오염수, 공방전  \n",
            "15              불합격, 수험생, 명, 행정심판, 제기, 신뢰이익, 침해  \n",
            "16                      비둘기, 준, 국채, 금리, 안정, 리스크  \n",
            "17                     데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "18                     데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "19                       금리, 패러다임, 주식, 줄, 채권, 때  \n",
            "20                             오이, 밭, 왓챠, 발끈, 만  \n",
            "21    민주당, 진, 교훈, 강서구, 청장, 당선, 뉴욕증시, 국채, 금리, 하락  \n",
            "22                      침체, 인플레, 불가능, 증시, 적, 거시  \n",
            "23                   좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "24                서프라이즈, 물가, 긴축, 우려, 환율, 안착, 시도  \n",
            "25            장기, 물, 국채, 경매, 부진, 국채, 금리, 다시, 꼬리  \n",
            "26                   꽃, 한글, 훈, 민정, 의, 친, 세계, 소셜  \n",
            "27           뉴욕증시, 물가, 보고서, 영향, 하락, 출근길, 안개, 조심  \n",
            "{'테슬라': 0, '매물': 0, '폭탄': 0, '애플': 0, '엔비디아': 0, '저가': 0, '매수': 0, '오염수': 0, '방류': 0, '런던': 0, '협약': 0, '해양': 0, '재판소': 0, '급부': 0, '이건희': 0, '회장': 0, '동물': 0, '사랑': 0, '주목': 0, '이유': 0, '베팅': 0, '종목': 0, '하락': 0, '마이너스': 0, '언제': 0, '사활': 0, '홀딩스': 0, '레이': 0, '거버넌스': 0, '중요성': 0, '알맹이': 0, '총회': 0, '냉전': 0, '구도': 0, '공방전': 0, '누적': 0, '스트리밍': 0, '세계': 0, '이용': 0, '연중': 0, '기획': 0, '브랜드': 0, '리포트': 0, '차트': 0, '공연': 0, '한국': 0, '음악': 0, '산업': 0, '불합격': 0, '수험생': 0, '행정심판': 0, '제기': 0, '신뢰이익': 0, '침해': 0, '비둘기': 0, '국채': 0, '금리': 0, '안정': 0, '리스크': 0, '데스크': 0, '칼럼': 0, '먹거리': 0, '물가': 0, '기후': 0, '위기': 0, '패러다임': 0, '주식': 0, '채권': 0, '오이': 0, '왓챠': 0, '발끈': 0, '민주당': 0, '교훈': 0, '강서구': 0, '청장': 0, '당선': 0, '뉴욕증시': 0, '침체': 0, '인플레': 0, '불가능': 0, '증시': 0, '거시': 0, '좀처럼': 0, '고물': 0, '연내': 0, '추가': 0, '인상': 0, '서프라이즈': 0, '긴축': 0, '우려': 0, '환율': 0, '안착': 0, '시도': 0, '장기': 0, '경매': 0, '부진': 0, '다시': 0, '꼬리': 0, '한글': 0, '민정': 0, '소셜': 0, '보고서': 0, '영향': 0, '출근길': 0, '안개': 0, '조심': 0}\n",
            "테슬라: 1\n",
            "매물: 1\n",
            "폭탄: 1\n",
            "애플: 1\n",
            "엔비디아: 1\n",
            "저가: 1\n",
            "매수: 1\n",
            "오염수: 4\n",
            "방류: 2\n",
            "런던: 4\n",
            "협약: 2\n",
            "해양: 2\n",
            "재판소: 2\n",
            "급부: 2\n",
            "이건희: 3\n",
            "회장: 3\n",
            "동물: 3\n",
            "사랑: 3\n",
            "주목: 3\n",
            "이유: 6\n",
            "베팅: 1\n",
            "종목: 1\n",
            "하락: 3\n",
            "마이너스: 1\n",
            "언제: 1\n",
            "사활: 3\n",
            "홀딩스: 1\n",
            "레이: 1\n",
            "거버넌스: 1\n",
            "중요성: 1\n",
            "알맹이: 2\n",
            "총회: 2\n",
            "냉전: 2\n",
            "구도: 2\n",
            "공방전: 2\n",
            "누적: 1\n",
            "스트리밍: 1\n",
            "세계: 2\n",
            "이용: 1\n",
            "연중: 2\n",
            "기획: 2\n",
            "브랜드: 2\n",
            "리포트: 2\n",
            "차트: 1\n",
            "공연: 1\n",
            "한국: 1\n",
            "음악: 1\n",
            "산업: 1\n",
            "불합격: 1\n",
            "수험생: 1\n",
            "행정심판: 1\n",
            "제기: 1\n",
            "신뢰이익: 1\n",
            "침해: 1\n",
            "비둘기: 1\n",
            "국채: 4\n",
            "금리: 5\n",
            "안정: 1\n",
            "리스크: 1\n",
            "데스크: 2\n",
            "칼럼: 2\n",
            "먹거리: 2\n",
            "물가: 4\n",
            "기후: 2\n",
            "위기: 2\n",
            "패러다임: 1\n",
            "주식: 1\n",
            "채권: 1\n",
            "오이: 1\n",
            "왓챠: 1\n",
            "발끈: 1\n",
            "민주당: 1\n",
            "교훈: 1\n",
            "강서구: 1\n",
            "청장: 1\n",
            "당선: 1\n",
            "뉴욕증시: 2\n",
            "침체: 1\n",
            "인플레: 1\n",
            "불가능: 1\n",
            "증시: 1\n",
            "거시: 1\n",
            "좀처럼: 1\n",
            "고물: 1\n",
            "연내: 1\n",
            "추가: 1\n",
            "인상: 1\n",
            "서프라이즈: 1\n",
            "긴축: 1\n",
            "우려: 1\n",
            "환율: 1\n",
            "안착: 1\n",
            "시도: 1\n",
            "장기: 1\n",
            "경매: 1\n",
            "부진: 1\n",
            "다시: 1\n",
            "꼬리: 1\n",
            "한글: 1\n",
            "민정: 1\n",
            "소셜: 1\n",
            "보고서: 1\n",
            "영향: 1\n",
            "출근길: 1\n",
            "안개: 1\n",
            "조심: 1\n",
            "\n",
            "Total number of words: 162\n",
            "up : 72\n",
            "down : 90\n",
            "{'테슬라': -0.4444444444444444, '매물': -0.4444444444444444, '폭탄': -0.4444444444444444, '애플': -0.4444444444444444, '엔비디아': -0.4444444444444444, '저가': -0.4444444444444444, '매수': -0.4444444444444444, '오염수': 2.2222222222222223, '방류': 1.1111111111111112, '런던': 2.2222222222222223, '협약': 1.1111111111111112, '해양': 1.1111111111111112, '재판소': 1.1111111111111112, '급부': 1.1111111111111112, '이건희': -1.3333333333333333, '회장': -1.3333333333333333, '동물': -1.3333333333333333, '사랑': -1.3333333333333333, '주목': -1.3333333333333333, '이유': -2.666666666666667, '베팅': -0.4444444444444444, '종목': -0.4444444444444444, '하락': -1.3333333333333333, '마이너스': -0.4444444444444444, '언제': -0.4444444444444444, '사활': -1.3333333333333333, '홀딩스': 0.5555555555555556, '레이': 0.5555555555555556, '거버넌스': 0.5555555555555556, '중요성': 0.5555555555555556, '알맹이': 1.1111111111111112, '총회': 1.1111111111111112, '냉전': 1.1111111111111112, '구도': 1.1111111111111112, '공방전': 1.1111111111111112, '누적': 0.5555555555555556, '스트리밍': 0.5555555555555556, '세계': 0.11111111111111116, '이용': 0.5555555555555556, '연중': 1.1111111111111112, '기획': 1.1111111111111112, '브랜드': 1.1111111111111112, '리포트': 1.1111111111111112, '차트': 0.5555555555555556, '공연': 0.5555555555555556, '한국': 0.5555555555555556, '음악': 0.5555555555555556, '산업': 0.5555555555555556, '불합격': 0.5555555555555556, '수험생': 0.5555555555555556, '행정심판': 0.5555555555555556, '제기': 0.5555555555555556, '신뢰이익': 0.5555555555555556, '침해': 0.5555555555555556, '비둘기': 0.5555555555555556, '국채': -0.7777777777777777, '금리': -1.222222222222222, '안정': 0.5555555555555556, '리스크': 0.5555555555555556, '데스크': 1.1111111111111112, '칼럼': 1.1111111111111112, '먹거리': 1.1111111111111112, '물가': 0.22222222222222232, '기후': 1.1111111111111112, '위기': 1.1111111111111112, '패러다임': -0.4444444444444444, '주식': -0.4444444444444444, '채권': -0.4444444444444444, '오이': -0.4444444444444444, '왓챠': -0.4444444444444444, '발끈': -0.4444444444444444, '민주당': -0.4444444444444444, '교훈': -0.4444444444444444, '강서구': -0.4444444444444444, '청장': -0.4444444444444444, '당선': -0.4444444444444444, '뉴욕증시': -0.8888888888888888, '침체': -0.4444444444444444, '인플레': -0.4444444444444444, '불가능': -0.4444444444444444, '증시': -0.4444444444444444, '거시': -0.4444444444444444, '좀처럼': -0.4444444444444444, '고물': -0.4444444444444444, '연내': -0.4444444444444444, '추가': -0.4444444444444444, '인상': -0.4444444444444444, '서프라이즈': -0.4444444444444444, '긴축': -0.4444444444444444, '우려': -0.4444444444444444, '환율': -0.4444444444444444, '안착': -0.4444444444444444, '시도': -0.4444444444444444, '장기': -0.4444444444444444, '경매': -0.4444444444444444, '부진': -0.4444444444444444, '다시': -0.4444444444444444, '꼬리': -0.4444444444444444, '한글': -0.4444444444444444, '민정': -0.4444444444444444, '소셜': -0.4444444444444444, '보고서': -0.4444444444444444, '영향': -0.4444444444444444, '출근길': -0.4444444444444444, '안개': -0.4444444444444444, '조심': -0.4444444444444444}\n",
            "감성 사전 평균 점수 :  -2.3042364662031552e-17\n",
            "          date  Up/Down  sent_score  sent_label  \\\n",
            "0   2023-09-18        0   -0.444444           0   \n",
            "1   2023-09-19        1    1.428571           1   \n",
            "2   2023-09-19        1    1.428571           1   \n",
            "3   2023-09-21        0   -1.555556           0   \n",
            "4   2023-09-21        0   -1.555556           0   \n",
            "5   2023-09-21        0   -1.555556           0   \n",
            "6   2023-09-25        0   -0.622222           0   \n",
            "7   2023-09-27        0   -2.000000           0   \n",
            "8   2023-09-27        0   -2.000000           0   \n",
            "9   2023-09-27        0   -2.000000           0   \n",
            "10  2023-10-05        1    0.555556           1   \n",
            "11  2023-10-10        1    1.428571           1   \n",
            "12  2023-10-10        1    0.777778           1   \n",
            "13  2023-10-10        1    0.802469           1   \n",
            "14  2023-10-10        1    1.428571           1   \n",
            "15  2023-10-10        1    0.555556           1   \n",
            "16  2023-10-11        1   -0.066667           0   \n",
            "17  2023-10-11        1    0.962963           1   \n",
            "18  2023-10-11        1    0.962963           1   \n",
            "19  2023-10-12        0   -0.638889           0   \n",
            "20  2023-10-12        0   -0.444444           0   \n",
            "21  2023-10-12        0   -0.716049           0   \n",
            "22  2023-10-13        0   -0.444444           0   \n",
            "23  2023-10-13        0   -0.574074           0   \n",
            "24  2023-10-13        0   -0.349206           0   \n",
            "25  2023-10-13        0   -0.625000           0   \n",
            "26  2023-10-13        0   -0.305556           0   \n",
            "27  2023-10-13        0   -0.527778           0   \n",
            "\n",
            "                                                title  \\\n",
            "0                   테슬라 270달러 넘자 매물 폭탄…애플-엔비디아는 저가 매수   \n",
            "1                    오염수 2차 방류 앞두고 런던협약‧해양재판소 급부상, 왜?   \n",
            "2                    오염수 2차 방류 앞두고 런던협약‧해양재판소 급부상, 왜?   \n",
            "3                            고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "4                            고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "5                            고 이건희 회장 ‘동물 사랑’ 주목받는 이유   \n",
            "6                   3억불 베팅했는데 사는 종목마다 하락…마이너스의 손 언제까지   \n",
            "7                                  SKT가 AI에 사활 건 이유는?   \n",
            "8                                  SKT가 AI에 사활 건 이유는?   \n",
            "9                                  SKT가 AI에 사활 건 이유는?   \n",
            "10                         KISCO홀딩스 '리레이팅'과 거버넌스의 중요성   \n",
            "11                    '알맹이' 없었던 런던총회…'신냉전 구도' 오염수 공방전   \n",
            "12   누적 스트리밍 5001억회… 전 세계인 63번씩 이용한 꼴 [연중기획-K브랜드 리포트]   \n",
            "13  ‘TOP 100’ 차트서 인디공연까지… 한국 음악산업 이끈다 [연중기획-K브랜드 리포트]   \n",
            "14                    '알맹이' 없었던 런던총회…'신냉전 구도' 오염수 공방전   \n",
            "15                 CPA 불합격 수험생 293명 행정심판 제기…\"신뢰이익 침해\"   \n",
            "16                      비둘기로 변한 연준?…국채 금리 안정에도 남은 리스크   \n",
            "17                                [데스크칼럼]먹거리 물가와 기후위기   \n",
            "18                                [데스크칼럼]먹거리 물가와 기후위기   \n",
            "19                     40년 금리 패러다임 끝났다…주식 줄이고 채권 늘릴 때   \n",
            "20                      '오이밭'된 왓챠, LG U+는 '신발끈'만 묶었을까   \n",
            "21                  민주당 진교훈 강서구청장 당선…뉴욕증시, 국채금리 하락에 ↑   \n",
            "22                     침체 없이는 2% 인플레 불가능?…증시에 적이 된 거시   \n",
            "23                     좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "24              서프라이즈 美 물가에 살아난 긴축 우려…환율 1350원대 안착 시도   \n",
            "25                          장기물 국채경매 부진…국채금리 다시 꼬리 든다   \n",
            "26                         꽃이 된 한글 훈민정花의 美친 세계화 [소셜+]   \n",
            "27               뉴욕증시, 9월 물가보고서 영향 하락…출근길, 짙은 안개 '조심'   \n",
            "\n",
            "                                          nouns  \n",
            "0                 테슬라, 매물, 폭탄, 애플, 엔비디아, 저가, 매수  \n",
            "1            오염수, 차, 방류, 런던, 협약, 해양, 재판소, 급부, 왜  \n",
            "2            오염수, 차, 방류, 런던, 협약, 해양, 재판소, 급부, 왜  \n",
            "3                    고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "4                    고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "5                    고, 이건희, 회장, 동물, 사랑, 주목, 이유  \n",
            "6                       베팅, 종목, 하락, 마이너스, 손, 언제  \n",
            "7                                     사활, 건, 이유  \n",
            "8                                     사활, 건, 이유  \n",
            "9                                     사활, 건, 이유  \n",
            "10                  홀딩스, 리, 레이, 팅, 과, 거버넌스, 중요성  \n",
            "11                알맹이, 런던, 총회, 냉전, 구도, 오염수, 공방전  \n",
            "12  누적, 스트리밍, 전, 세계, 번, 이용, 꼴, 연중, 기획, 브랜드, 리포트  \n",
            "13         차트, 공연, 한국, 음악, 산업, 연중, 기획, 브랜드, 리포트  \n",
            "14                알맹이, 런던, 총회, 냉전, 구도, 오염수, 공방전  \n",
            "15              불합격, 수험생, 명, 행정심판, 제기, 신뢰이익, 침해  \n",
            "16                      비둘기, 준, 국채, 금리, 안정, 리스크  \n",
            "17                     데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "18                     데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "19                       금리, 패러다임, 주식, 줄, 채권, 때  \n",
            "20                             오이, 밭, 왓챠, 발끈, 만  \n",
            "21    민주당, 진, 교훈, 강서구, 청장, 당선, 뉴욕증시, 국채, 금리, 하락  \n",
            "22                      침체, 인플레, 불가능, 증시, 적, 거시  \n",
            "23                   좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "24                서프라이즈, 물가, 긴축, 우려, 환율, 안착, 시도  \n",
            "25            장기, 물, 국채, 경매, 부진, 국채, 금리, 다시, 꼬리  \n",
            "26                   꽃, 한글, 훈, 민정, 의, 친, 세계, 소셜  \n",
            "27           뉴욕증시, 물가, 보고서, 영향, 하락, 출근길, 안개, 조심  \n",
            "Epoch 1/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.5455\n",
            "Epoch 1: val_acc improved from -inf to 1.00000, saving model to best_model.h5\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.6945 - acc: 0.5455 - val_loss: 0.6321 - val_acc: 1.0000\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6860 - acc: 0.5455\n",
            "Epoch 2: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.6860 - acc: 0.5455 - val_loss: 0.6122 - val_acc: 1.0000\n",
            "Epoch 3/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - ETA: 0s - loss: 0.6807 - acc: 0.5455\n",
            "Epoch 3: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.6807 - acc: 0.5455 - val_loss: 0.6035 - val_acc: 1.0000\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6753 - acc: 0.5455\n",
            "Epoch 4: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.6753 - acc: 0.5455 - val_loss: 0.5993 - val_acc: 1.0000\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6689 - acc: 0.5455\n",
            "Epoch 5: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.6689 - acc: 0.5455 - val_loss: 0.5961 - val_acc: 1.0000\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6612 - acc: 0.5455\n",
            "Epoch 6: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.6612 - acc: 0.5455 - val_loss: 0.5925 - val_acc: 1.0000\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6515 - acc: 0.5455\n",
            "Epoch 7: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.6515 - acc: 0.5455 - val_loss: 0.5878 - val_acc: 1.0000\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6395 - acc: 0.5455\n",
            "Epoch 8: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.6395 - acc: 0.5455 - val_loss: 0.5818 - val_acc: 1.0000\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6246 - acc: 0.5455\n",
            "Epoch 9: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.6246 - acc: 0.5455 - val_loss: 0.5754 - val_acc: 1.0000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6065 - acc: 0.5909\n",
            "Epoch 10: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.6065 - acc: 0.5909 - val_loss: 0.5713 - val_acc: 1.0000\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5848 - acc: 0.8182\n",
            "Epoch 11: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.5848 - acc: 0.8182 - val_loss: 0.5700 - val_acc: 1.0000\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5594 - acc: 0.8182\n",
            "Epoch 12: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.5594 - acc: 0.8182 - val_loss: 0.5693 - val_acc: 1.0000\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5296 - acc: 0.9091\n",
            "Epoch 13: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.5296 - acc: 0.9091 - val_loss: 0.5743 - val_acc: 1.0000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4949 - acc: 0.9545\n",
            "Epoch 14: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4949 - acc: 0.9545 - val_loss: 0.5499 - val_acc: 1.0000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4553 - acc: 0.9545\n",
            "Epoch 15: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.4553 - acc: 0.9545 - val_loss: 0.8132 - val_acc: 0.0000e+00\n",
            "4/4 [==============================] - 1s 21ms/step\n",
            "미래 주식 시장은 긍정적으로 움직일 것으로 예상됩니다.\n",
            "긍정적 뉴스 수: 76 (73.08%)\n",
            "부정적 뉴스 수: 28 (26.92%)\n",
            "\n",
            "긍정적 뉴스 예시:\n",
            "- 코리아 스마트 그리드 엑스포 18일 코엑스서 개막\n",
            "- 인천시, 섬 관광으로 외래 관광객·국제행사 유치 경쟁력 높인다.\n",
            "- 조진훈 제주CVB 팀장 '세계표준의 날' 장관상 수상\n",
            "- 벡스코 獨 최대 전시회사 '메쎄 프랑크푸르트'와 협력 확대 나서\n",
            "- 삼성 사회공헌 ‘요란한 빈수레’ 안 되려면…“윤리 임원 두고, 철학자 뽑아야”\n",
            "\n",
            "부정적 뉴스 예시:\n",
            "- 아직도 탄탄한 미국 소비...그런데 주가는 왜 부진?\n",
            "- 좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?\n",
            "- [굿모닝 증시]美 소비 증가, 반도체 규제 우려…코스피 하락 출발 예상\n",
            "- [굿모닝 증시]실적 기대에 美 증시 상승…\"코스피 상승 출발 전망\"\n",
            "- [굿모닝 증시]이·팔 전쟁 불안…코스피 하락 출발 전망\n"
          ]
        }
      ],
      "source": [
        "# 뉴스 제목, 일자 크롤링\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101&date=\"\n",
        "\n",
        "# 1. User-Agent를 설정\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# 시작 날짜와 종료 날짜 설정\n",
        "start_date = datetime.datetime.now() - datetime.timedelta(days=30)\n",
        "end_date = datetime.datetime.now() - datetime.timedelta(days=5)\n",
        "\n",
        "current_date = start_date\n",
        "\n",
        "news_data = []\n",
        "\n",
        "while current_date <= end_date:\n",
        "    # 2. 요청을 보낼 때 headers 추가\n",
        "    response = requests.get(base_url + current_date.strftime('%Y%m%d'), headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    for item in soup.select(\".cluster_text a\"):\n",
        "        title = item.text.strip()\n",
        "        if item.attrs[\"href\"].startswith(\"http\"):\n",
        "            news_url = item.attrs[\"href\"]\n",
        "        else:\n",
        "            news_url = \"https:\" + item.attrs[\"href\"]\n",
        "\n",
        "        detail_response = requests.get(news_url, headers=headers)  # headers 추가\n",
        "        detail_soup = BeautifulSoup(detail_response.text, 'html.parser')\n",
        "        date_element = detail_soup.select_one(\"span.media_end_head_info_datestamp_time\")\n",
        "        date = date_element.attrs[\"data-date-time\"].split()[0]\n",
        "\n",
        "        news_data.append({\n",
        "            'title': title,\n",
        "            'date': date\n",
        "        })\n",
        "\n",
        "        # 요청 간에 약간의 지연을 두어 IP 차단을 피하기\n",
        "        time.sleep(1.5)\n",
        "\n",
        "    # 다음 날짜로 이동\n",
        "    current_date += datetime.timedelta(days=1)\n",
        "\n",
        "# 뉴스 데이터를 날짜 순으로 정렬\n",
        "news_data_sorted = sorted(news_data, key=lambda x: x['date'])\n",
        "\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "news_df = pd.DataFrame(news_data_sorted, columns=['date', 'title'])\n",
        "\n",
        "# 시작 날짜와 종료 날짜를 문자열로 변환\n",
        "start_date_str = start_date.strftime('%Y-%m-%d')\n",
        "end_date_str = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "# 원하는 날짜 범위만 선택\n",
        "news_df = news_df[(news_df['date'] >= start_date_str) & (news_df['date'] <= end_date_str)]\n",
        "\n",
        "!pip install konlpy\n",
        "\n",
        "# 크롤링한 뉴스 제목 명사 추출\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "# Okt 객체 초기화\n",
        "okt = Okt()\n",
        "\n",
        "# 제목에서 명사만 추출하는 함수\n",
        "def extract_nouns(title):\n",
        "    return ', '.join(okt.nouns(title))\n",
        "\n",
        "# 'title' 열의 각 제목에 대하여 명사만 추출\n",
        "news_df['nouns'] = news_df['title'].apply(extract_nouns)\n",
        "\n",
        "print(news_df)\n",
        "\n",
        "# 코스피 등락율 - 뉴스\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def get_kospi_closing_prices():\n",
        "    url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSPI\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    kospi_closings = []\n",
        "\n",
        "    for i in range(1, 7):\n",
        "        response = requests.get(url + f\"&page={i}\", headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        dates = soup.select(\".date\")\n",
        "        closings = soup.select(\".number_1\")\n",
        "\n",
        "        for d, c in zip(dates, closings[::4]):  # 종가만 가져오기 위해 slicing 사용\n",
        "            kospi_closings.append([d.text.strip(), float(c.text.replace(',', ''))])\n",
        "\n",
        "    return kospi_closings\n",
        "\n",
        "kospi_data = get_kospi_closing_prices()\n",
        "df = pd.DataFrame(kospi_data, columns=[\"Date\", \"Closing\"])\n",
        "\n",
        "# Shift를 사용해 다음 날짜의 종가를 가져와서 현재 날짜와 비교\n",
        "# 예: 10월 9일 종가보다 10월 10일 종가가 더 높다면 10월 9일 등락율 1이 됨\n",
        "\n",
        "df[\"Up/Down\"] = (df[\"Closing\"].shift(1) > df[\"Closing\"]).astype(int)\n",
        "\n",
        "# 날짜 기준으로 최근 30일의 데이터를 가져온 후, 정렬\n",
        "df = df.sort_values(by=\"Date\").tail(30).reset_index(drop=True)\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%Y.%m.%d').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "print(df)\n",
        "\n",
        "merged_df = pd.merge(news_df, df, left_on='date', right_on='Date', how='inner')\n",
        "merged_df = merged_df[['date', 'Up/Down', 'title', 'nouns']]\n",
        "print(merged_df)\n",
        "\n",
        "# 단어 점수 초기화 및 개수\n",
        "# 한 글자 제외 -> 두 글자 이상 단어\n",
        "\n",
        "# 'nouns' 칼럼의 값을 문자열로 변환\n",
        "df['nouns'] = merged_df['nouns'].astype(str)\n",
        "df = df.dropna(subset=['nouns'])\n",
        "\n",
        "# 'filtered_nouns' 컬럼 생성\n",
        "merged_df['filtered_nouns'] = merged_df['nouns'].apply(lambda x: [word for word in x.split(', ') if len(word) > 1])\n",
        "\n",
        "# 단어 점수 초기화\n",
        "word_scores = {word: 0 for word_list in merged_df['filtered_nouns'] for word in word_list}\n",
        "print(word_scores)\n",
        "\n",
        "# 단어 빈도수 계산\n",
        "from collections import Counter\n",
        "word_counts = Counter(word for word_list in merged_df['filtered_nouns'] for word in word_list)\n",
        "\n",
        "# 결과 출력\n",
        "for word, count in word_counts.items():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# 단어 점수 부여\n",
        "\n",
        "# 전체 단어 개수 출력\n",
        "total_words = sum(word_counts.values())\n",
        "print(f\"\\nTotal number of words: {total_words}\")\n",
        "\n",
        "# Up/Down 값이 1인 데이터에서 포함된 단어의 리스트\n",
        "up = []\n",
        "for nouns in merged_df[merged_df['Up/Down'] == 1]['filtered_nouns']:\n",
        "    up.extend(nouns)\n",
        "\n",
        "# Up/Down 값이 0인 데이터에서 포함된 단어의 리스트\n",
        "down = []\n",
        "for nouns in merged_df[merged_df['Up/Down'] == 0]['filtered_nouns']:\n",
        "    down.extend(nouns)\n",
        "\n",
        "print(\"up :\", len(up))\n",
        "print(\"down :\", len(down))\n",
        "\n",
        "# 상승 비율과 하락 비율 계산\n",
        "total_words = len(up) + len(down)\n",
        "up_ratio = len(up) / total_words\n",
        "down_ratio = len(down) / total_words\n",
        "\n",
        "# 단어 점수 초기화\n",
        "word_scores = {word: 0 for word in word_scores.keys()}  # 기존의 word_scores 딕셔너리 사용\n",
        "\n",
        "# Up(1) 데이터의 단어들에 대해서 하락 비율을 더해주기\n",
        "for word in up:\n",
        "    if word in word_scores:\n",
        "        word_scores[word] += down_ratio\n",
        "\n",
        "# Down(0) 데이터의 단어들에 대해서 상승 비율을 차감해주기\n",
        "for word in down:\n",
        "    if word in word_scores:\n",
        "        word_scores[word] -= up_ratio\n",
        "\n",
        "# 결과 확인\n",
        "print(word_scores)\n",
        "\n",
        "# 감성 사전 완료\n",
        "\n",
        "total = []\n",
        "for nouns in merged_df['filtered_nouns']:\n",
        "    sent_score = 0\n",
        "    for noun in nouns:\n",
        "        if noun in word_scores:\n",
        "            sent_score += word_scores[noun]\n",
        "\n",
        "    # 해당 뉴스 제목에 포함된 단어의 수로 나누어 평균 점수를 계산\n",
        "    avg_sent_score = sent_score / len(nouns) if nouns else 0  # 단어가 없는 경우 0으로 처리\n",
        "    total.append(avg_sent_score)\n",
        "\n",
        "merged_df['sent_score'] = total\n",
        "\n",
        "# 감성사전의 평균 점수 계산\n",
        "\n",
        "sent_mean = sum(word_scores.values()) / len(word_scores)\n",
        "print('감성 사전 평균 점수 : ',sent_mean)\n",
        "\n",
        "# 감성 점수 계산\n",
        "def calculate_sentiment_score(noun_list):\n",
        "    score = 0\n",
        "    for noun in noun_list:\n",
        "        if noun in word_scores:\n",
        "            score += word_scores[noun]\n",
        "    return score / (len(noun_list) if len(noun_list) != 0 else 1)\n",
        "\n",
        "merged_df['sent_score'] = merged_df['filtered_nouns'].apply(calculate_sentiment_score)\n",
        "\n",
        "# 평균 점수를 기준으로 라벨링\n",
        "merged_df['sent_label'] = merged_df['sent_score'].apply(lambda x: 1 if x > sent_mean else 0)\n",
        "\n",
        "\n",
        "\n",
        "result_df = merged_df[['date', 'Up/Down', 'sent_score', 'sent_label', 'title', 'nouns']]\n",
        "print(result_df)\n",
        "\n",
        "# 모델링\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. 데이터 준비\n",
        "X_data = merged_df['nouns'].apply(lambda x: ' '.join([word for word in x.split(', ') if len(word) > 1])).values\n",
        "Y_data = merged_df['sent_label'].values  # 기존의 'merged_df'를 사용\n",
        "\n",
        "# 2. 토큰화 및 패딩\n",
        "vocab_size = 2000\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(X_data)\n",
        "X_tokenized = tokenizer.texts_to_sequences(X_data)\n",
        "X_padded = pad_sequences(X_tokenized, maxlen=30)\n",
        "\n",
        "# 3. Bi-LSTM 모델 구축 및 훈련\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_padded, Y_data, epochs=15, callbacks=[es, mc], batch_size=256, validation_split=0.2)\n",
        "\n",
        "# 최신 뉴스 크롤링 후 모델에 적용해서 최종 결과 확\n",
        "\n",
        "# 뉴스 제목 크롤링\n",
        "base_url = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101&date=\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "start_date = datetime.datetime.now() - datetime.timedelta(days=30)\n",
        "end_date = datetime.datetime.now() - datetime.timedelta(days=5)\n",
        "current_date = start_date\n",
        "\n",
        "news_data = []\n",
        "\n",
        "while current_date <= end_date:\n",
        "    response = requests.get(base_url + current_date.strftime('%Y%m%d'), headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    for item in soup.select(\".cluster_text a\"):\n",
        "        title = item.text.strip()\n",
        "        news_data.append({\n",
        "            'date': current_date.strftime('%Y-%m-%d'),\n",
        "            'title': title\n",
        "        })\n",
        "    current_date += datetime.timedelta(days=1)\n",
        "\n",
        "news_df = pd.DataFrame(news_data, columns=['date', 'title'])\n",
        "\n",
        "# 명사 추출\n",
        "okt = Okt()\n",
        "news_df['nouns'] = news_df['title'].apply(lambda x: ', '.join(okt.nouns(x)))\n",
        "\n",
        "# 감성 사전과 비교하여 감성 점수 계산\n",
        "news_df['filtered_nouns'] = news_df['nouns'].apply(lambda x: [word for word in x.split(', ') if len(word) > 1])\n",
        "news_df['sent_score'] = news_df['filtered_nouns'].apply(calculate_sentiment_score)  # 이전에 정의한 함수\n",
        "\n",
        "# 예측을 위한 데이터 전처리\n",
        "X_test_tokenized = tokenizer.texts_to_sequences(news_df['nouns'].apply(lambda x: ' '.join([word for word in x.split(', ') if len(word) > 1])).values)\n",
        "X_test_padded = pad_sequences(X_test_tokenized, maxlen=30)\n",
        "\n",
        "# 훈련된 Bi-LSTM 모델로 예측\n",
        "predicted = model.predict(X_test_padded)\n",
        "news_df['predicted_label'] = (predicted > 0.5).astype(int)\n",
        "\n",
        "# 결과 출력\n",
        "positive_news_ratio = news_df['predicted_label'].sum() / len(news_df)\n",
        "if positive_news_ratio > 0.5:\n",
        "    print(\"미래 주식 시장은 긍정적으로 움직일 것으로 예상됩니다.\")\n",
        "else:\n",
        "    print(\"미래 주식 시장은 부정적으로 움직일 것으로 예상됩니다.\")\n",
        "\n",
        "    # 각 뉴스의 감성 점수를 바탕으로 긍정적 및 부정적 뉴스 개수 확인 및 출력\n",
        "sent_mean = news_df['sent_score'].mean()\n",
        "\n",
        "pos_news = len(news_df[news_df['sent_score'] > sent_mean])\n",
        "neg_news = len(news_df[news_df['sent_score'] <= sent_mean])\n",
        "total_news = len(news_df)\n",
        "\n",
        "print(f\"긍정적 뉴스 수: {pos_news} ({pos_news/total_news*100:.2f}%)\")\n",
        "print(f\"부정적 뉴스 수: {neg_news} ({neg_news/total_news*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n긍정적 뉴스 예시:\")\n",
        "for title in news_df[news_df['sent_score'] > sent_mean]['title'].head(5):\n",
        "    print(\"-\", title)\n",
        "\n",
        "print(\"\\n부정적 뉴스 예시:\")\n",
        "for title in news_df[news_df['sent_score'] <= sent_mean]['title'].head(5):\n",
        "    print(\"-\", title)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfKZkEIAUkAXcCNKqAla7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}