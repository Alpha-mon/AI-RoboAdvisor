{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmUNFCyRxrW4Yx4JCM+Gfm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alpha-mon/AI-RoboAdvisor/blob/main/PortfolioOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CvVcU1x7AyBa",
        "outputId": "af38fcce-c3ba-4eff-b619-1d33952a2f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "보유하고 있는 주식의 티커 목록을 쉼표로 구분하여 입력하세요 (예: AAPL,GOOGL,MSFT): 005930.KS,LPL,NVDA\n",
            "Epoch 1/100\n",
            "159/159 - 1s - loss: 0.0313 - 1s/epoch - 9ms/step\n",
            "Epoch 2/100\n",
            "159/159 - 0s - loss: 0.0277 - 261ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "159/159 - 0s - loss: 0.0251 - 251ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "159/159 - 0s - loss: 0.0255 - 263ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "159/159 - 0s - loss: 0.0263 - 266ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "159/159 - 0s - loss: 0.0247 - 275ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "159/159 - 0s - loss: 0.0253 - 268ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "159/159 - 0s - loss: 0.0255 - 264ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "159/159 - 0s - loss: 0.0260 - 245ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "159/159 - 0s - loss: 0.0245 - 242ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "159/159 - 0s - loss: 0.0243 - 254ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "159/159 - 0s - loss: 0.0244 - 275ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "159/159 - 0s - loss: 0.0243 - 300ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "159/159 - 0s - loss: 0.0253 - 331ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "159/159 - 0s - loss: 0.0247 - 310ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "159/159 - 0s - loss: 0.0229 - 289ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "159/159 - 0s - loss: 0.0247 - 327ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "159/159 - 0s - loss: 0.0236 - 287ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "159/159 - 0s - loss: 0.0239 - 235ms/epoch - 1ms/step\n",
            "Epoch 20/100\n",
            "159/159 - 0s - loss: 0.0241 - 240ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "159/159 - 0s - loss: 0.0239 - 262ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "159/159 - 0s - loss: 0.0241 - 240ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "159/159 - 0s - loss: 0.0244 - 245ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "159/159 - 0s - loss: 0.0239 - 243ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "159/159 - 0s - loss: 0.0240 - 242ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "159/159 - 0s - loss: 0.0239 - 245ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "159/159 - 0s - loss: 0.0235 - 240ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "159/159 - 0s - loss: 0.0233 - 256ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "159/159 - 0s - loss: 0.0236 - 257ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "159/159 - 0s - loss: 0.0239 - 254ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "159/159 - 0s - loss: 0.0240 - 237ms/epoch - 1ms/step\n",
            "Epoch 32/100\n",
            "159/159 - 0s - loss: 0.0237 - 259ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "159/159 - 0s - loss: 0.0237 - 244ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "159/159 - 0s - loss: 0.0234 - 243ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "159/159 - 0s - loss: 0.0236 - 246ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "159/159 - 0s - loss: 0.0236 - 243ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "159/159 - 0s - loss: 0.0241 - 248ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "159/159 - 0s - loss: 0.0240 - 250ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "159/159 - 0s - loss: 0.0236 - 248ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "159/159 - 0s - loss: 0.0236 - 253ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "159/159 - 0s - loss: 0.0239 - 258ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "159/159 - 0s - loss: 0.0238 - 242ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "159/159 - 0s - loss: 0.0235 - 248ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "159/159 - 0s - loss: 0.0227 - 264ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "159/159 - 0s - loss: 0.0236 - 269ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "159/159 - 0s - loss: 0.0234 - 262ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "159/159 - 0s - loss: 0.0247 - 254ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "159/159 - 0s - loss: 0.0234 - 255ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "159/159 - 0s - loss: 0.0233 - 243ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "159/159 - 0s - loss: 0.0236 - 240ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "159/159 - 0s - loss: 0.0234 - 246ms/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "159/159 - 0s - loss: 0.0236 - 261ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "159/159 - 0s - loss: 0.0233 - 259ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "159/159 - 0s - loss: 0.0231 - 253ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "159/159 - 0s - loss: 0.0233 - 244ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "159/159 - 0s - loss: 0.0235 - 254ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "159/159 - 0s - loss: 0.0237 - 282ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "159/159 - 0s - loss: 0.0229 - 341ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "159/159 - 0s - loss: 0.0233 - 337ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "159/159 - 0s - loss: 0.0228 - 353ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "159/159 - 0s - loss: 0.0233 - 333ms/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "159/159 - 0s - loss: 0.0233 - 305ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "159/159 - 0s - loss: 0.0230 - 247ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "159/159 - 0s - loss: 0.0233 - 250ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "159/159 - 0s - loss: 0.0231 - 252ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "159/159 - 0s - loss: 0.0229 - 256ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "159/159 - 0s - loss: 0.0233 - 244ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "159/159 - 0s - loss: 0.0228 - 237ms/epoch - 1ms/step\n",
            "Epoch 69/100\n",
            "159/159 - 0s - loss: 0.0228 - 250ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "159/159 - 0s - loss: 0.0229 - 241ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "159/159 - 0s - loss: 0.0229 - 243ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "159/159 - 0s - loss: 0.0225 - 240ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "159/159 - 0s - loss: 0.0230 - 254ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "159/159 - 0s - loss: 0.0230 - 260ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "159/159 - 0s - loss: 0.0231 - 239ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "159/159 - 0s - loss: 0.0223 - 240ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "159/159 - 0s - loss: 0.0226 - 251ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "159/159 - 0s - loss: 0.0222 - 245ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "159/159 - 0s - loss: 0.0224 - 252ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "159/159 - 0s - loss: 0.0225 - 236ms/epoch - 1ms/step\n",
            "Epoch 81/100\n",
            "159/159 - 0s - loss: 0.0232 - 248ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "159/159 - 0s - loss: 0.0228 - 243ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "159/159 - 0s - loss: 0.0225 - 230ms/epoch - 1ms/step\n",
            "Epoch 84/100\n",
            "159/159 - 0s - loss: 0.0225 - 253ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "159/159 - 0s - loss: 0.0226 - 241ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "159/159 - 0s - loss: 0.0225 - 259ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "159/159 - 0s - loss: 0.0218 - 243ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "159/159 - 0s - loss: 0.0235 - 251ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "159/159 - 0s - loss: 0.0225 - 250ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "159/159 - 0s - loss: 0.0221 - 249ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "159/159 - 0s - loss: 0.0226 - 244ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "159/159 - 0s - loss: 0.0222 - 253ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "159/159 - 0s - loss: 0.0224 - 233ms/epoch - 1ms/step\n",
            "Epoch 94/100\n",
            "159/159 - 0s - loss: 0.0222 - 247ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "159/159 - 0s - loss: 0.0218 - 252ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "159/159 - 0s - loss: 0.0222 - 287ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "159/159 - 0s - loss: 0.0221 - 246ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "159/159 - 0s - loss: 0.0223 - 258ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "159/159 - 0s - loss: 0.0224 - 233ms/epoch - 1ms/step\n",
            "Epoch 100/100\n",
            "159/159 - 0s - loss: 0.0221 - 260ms/epoch - 2ms/step\n",
            "Epoch 1/100\n",
            "161/161 - 2s - loss: 0.0397 - 2s/epoch - 11ms/step\n",
            "Epoch 2/100\n",
            "161/161 - 0s - loss: 0.0284 - 277ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "161/161 - 0s - loss: 0.0280 - 248ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "161/161 - 0s - loss: 0.0285 - 242ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "161/161 - 0s - loss: 0.0280 - 241ms/epoch - 1ms/step\n",
            "Epoch 6/100\n",
            "161/161 - 0s - loss: 0.0274 - 254ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "161/161 - 0s - loss: 0.0265 - 271ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "161/161 - 0s - loss: 0.0269 - 252ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "161/161 - 0s - loss: 0.0275 - 242ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "161/161 - 0s - loss: 0.0270 - 260ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "161/161 - 0s - loss: 0.0270 - 262ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "161/161 - 0s - loss: 0.0264 - 248ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "161/161 - 0s - loss: 0.0256 - 254ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "161/161 - 0s - loss: 0.0261 - 248ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "161/161 - 0s - loss: 0.0261 - 254ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "161/161 - 0s - loss: 0.0263 - 243ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "161/161 - 0s - loss: 0.0260 - 264ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "161/161 - 0s - loss: 0.0263 - 230ms/epoch - 1ms/step\n",
            "Epoch 19/100\n",
            "161/161 - 0s - loss: 0.0256 - 270ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "161/161 - 0s - loss: 0.0260 - 247ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "161/161 - 0s - loss: 0.0260 - 251ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "161/161 - 0s - loss: 0.0257 - 258ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "161/161 - 0s - loss: 0.0261 - 249ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "161/161 - 0s - loss: 0.0264 - 256ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "161/161 - 0s - loss: 0.0256 - 250ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "161/161 - 0s - loss: 0.0259 - 257ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "161/161 - 0s - loss: 0.0256 - 251ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "161/161 - 0s - loss: 0.0261 - 254ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "161/161 - 0s - loss: 0.0254 - 251ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "161/161 - 0s - loss: 0.0258 - 266ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "161/161 - 0s - loss: 0.0261 - 264ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "161/161 - 0s - loss: 0.0260 - 249ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "161/161 - 0s - loss: 0.0261 - 253ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "161/161 - 0s - loss: 0.0253 - 272ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "161/161 - 0s - loss: 0.0268 - 237ms/epoch - 1ms/step\n",
            "Epoch 36/100\n",
            "161/161 - 0s - loss: 0.0252 - 256ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "161/161 - 0s - loss: 0.0257 - 285ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "161/161 - 0s - loss: 0.0257 - 283ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "161/161 - 0s - loss: 0.0254 - 235ms/epoch - 1ms/step\n",
            "Epoch 40/100\n",
            "161/161 - 0s - loss: 0.0257 - 256ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "161/161 - 0s - loss: 0.0253 - 311ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "161/161 - 0s - loss: 0.0255 - 316ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "161/161 - 0s - loss: 0.0252 - 312ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "161/161 - 0s - loss: 0.0256 - 296ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "161/161 - 0s - loss: 0.0256 - 332ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "161/161 - 0s - loss: 0.0253 - 327ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "161/161 - 0s - loss: 0.0254 - 241ms/epoch - 1ms/step\n",
            "Epoch 48/100\n",
            "161/161 - 0s - loss: 0.0254 - 262ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "161/161 - 0s - loss: 0.0258 - 250ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "161/161 - 0s - loss: 0.0253 - 254ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "161/161 - 0s - loss: 0.0252 - 262ms/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "161/161 - 0s - loss: 0.0253 - 249ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "161/161 - 0s - loss: 0.0254 - 295ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "161/161 - 0s - loss: 0.0254 - 258ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "161/161 - 0s - loss: 0.0257 - 246ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "161/161 - 0s - loss: 0.0255 - 252ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "161/161 - 0s - loss: 0.0256 - 287ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "161/161 - 0s - loss: 0.0255 - 255ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "161/161 - 0s - loss: 0.0252 - 258ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "161/161 - 0s - loss: 0.0249 - 251ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "161/161 - 0s - loss: 0.0252 - 241ms/epoch - 1ms/step\n",
            "Epoch 62/100\n",
            "161/161 - 0s - loss: 0.0254 - 234ms/epoch - 1ms/step\n",
            "Epoch 63/100\n",
            "161/161 - 0s - loss: 0.0259 - 257ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "161/161 - 0s - loss: 0.0253 - 264ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "161/161 - 0s - loss: 0.0252 - 299ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "161/161 - 0s - loss: 0.0246 - 277ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "161/161 - 0s - loss: 0.0249 - 248ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "161/161 - 0s - loss: 0.0252 - 251ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "161/161 - 0s - loss: 0.0249 - 246ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "161/161 - 0s - loss: 0.0253 - 254ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "161/161 - 0s - loss: 0.0255 - 264ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "161/161 - 0s - loss: 0.0248 - 265ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "161/161 - 0s - loss: 0.0250 - 251ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "161/161 - 0s - loss: 0.0254 - 249ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "161/161 - 0s - loss: 0.0251 - 255ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "161/161 - 0s - loss: 0.0249 - 255ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "161/161 - 0s - loss: 0.0248 - 254ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "161/161 - 0s - loss: 0.0255 - 254ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "161/161 - 0s - loss: 0.0253 - 288ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "161/161 - 0s - loss: 0.0251 - 258ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "161/161 - 0s - loss: 0.0251 - 251ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "161/161 - 0s - loss: 0.0248 - 260ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "161/161 - 0s - loss: 0.0248 - 254ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "161/161 - 0s - loss: 0.0247 - 247ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "161/161 - 0s - loss: 0.0246 - 312ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "161/161 - 0s - loss: 0.0251 - 312ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "161/161 - 0s - loss: 0.0249 - 323ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "161/161 - 0s - loss: 0.0248 - 320ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "161/161 - 0s - loss: 0.0249 - 342ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "161/161 - 0s - loss: 0.0249 - 290ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "161/161 - 0s - loss: 0.0250 - 240ms/epoch - 1ms/step\n",
            "Epoch 92/100\n",
            "161/161 - 0s - loss: 0.0247 - 263ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "161/161 - 0s - loss: 0.0244 - 245ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "161/161 - 0s - loss: 0.0247 - 247ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "161/161 - 0s - loss: 0.0240 - 239ms/epoch - 1ms/step\n",
            "Epoch 96/100\n",
            "161/161 - 0s - loss: 0.0239 - 262ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "161/161 - 0s - loss: 0.0238 - 268ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "161/161 - 0s - loss: 0.0241 - 272ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "161/161 - 0s - loss: 0.0230 - 249ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "161/161 - 0s - loss: 0.0234 - 267ms/epoch - 2ms/step\n",
            "Epoch 1/100\n",
            "161/161 - 1s - loss: 0.0197 - 1s/epoch - 9ms/step\n",
            "Epoch 2/100\n",
            "161/161 - 0s - loss: 0.0158 - 237ms/epoch - 1ms/step\n",
            "Epoch 3/100\n",
            "161/161 - 0s - loss: 0.0155 - 249ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "161/161 - 0s - loss: 0.0162 - 232ms/epoch - 1ms/step\n",
            "Epoch 5/100\n",
            "161/161 - 0s - loss: 0.0153 - 244ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "161/161 - 0s - loss: 0.0158 - 262ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "161/161 - 0s - loss: 0.0153 - 239ms/epoch - 1ms/step\n",
            "Epoch 8/100\n",
            "161/161 - 0s - loss: 0.0147 - 239ms/epoch - 1ms/step\n",
            "Epoch 9/100\n",
            "161/161 - 0s - loss: 0.0150 - 251ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "161/161 - 0s - loss: 0.0150 - 266ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "161/161 - 0s - loss: 0.0150 - 257ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "161/161 - 0s - loss: 0.0149 - 239ms/epoch - 1ms/step\n",
            "Epoch 13/100\n",
            "161/161 - 0s - loss: 0.0157 - 250ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "161/161 - 0s - loss: 0.0150 - 251ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "161/161 - 0s - loss: 0.0151 - 252ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "161/161 - 0s - loss: 0.0147 - 246ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "161/161 - 0s - loss: 0.0142 - 255ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "161/161 - 0s - loss: 0.0147 - 251ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "161/161 - 0s - loss: 0.0150 - 250ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "161/161 - 0s - loss: 0.0141 - 236ms/epoch - 1ms/step\n",
            "Epoch 21/100\n",
            "161/161 - 0s - loss: 0.0150 - 268ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "161/161 - 0s - loss: 0.0146 - 241ms/epoch - 1ms/step\n",
            "Epoch 23/100\n",
            "161/161 - 0s - loss: 0.0141 - 251ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "161/161 - 0s - loss: 0.0148 - 291ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "161/161 - 0s - loss: 0.0146 - 340ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "161/161 - 0s - loss: 0.0143 - 316ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "161/161 - 0s - loss: 0.0141 - 309ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "161/161 - 0s - loss: 0.0145 - 355ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "161/161 - 0s - loss: 0.0145 - 319ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "161/161 - 0s - loss: 0.0140 - 271ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "161/161 - 0s - loss: 0.0141 - 253ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "161/161 - 0s - loss: 0.0143 - 250ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "161/161 - 0s - loss: 0.0142 - 251ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "161/161 - 0s - loss: 0.0143 - 235ms/epoch - 1ms/step\n",
            "Epoch 35/100\n",
            "161/161 - 0s - loss: 0.0141 - 245ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "161/161 - 0s - loss: 0.0140 - 243ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "161/161 - 0s - loss: 0.0140 - 254ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "161/161 - 0s - loss: 0.0145 - 249ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "161/161 - 0s - loss: 0.0141 - 268ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "161/161 - 0s - loss: 0.0146 - 269ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "161/161 - 0s - loss: 0.0140 - 251ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "161/161 - 0s - loss: 0.0138 - 253ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "161/161 - 0s - loss: 0.0140 - 258ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "161/161 - 0s - loss: 0.0142 - 289ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "161/161 - 0s - loss: 0.0143 - 246ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "161/161 - 0s - loss: 0.0140 - 241ms/epoch - 1ms/step\n",
            "Epoch 47/100\n",
            "161/161 - 0s - loss: 0.0139 - 245ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "161/161 - 0s - loss: 0.0140 - 231ms/epoch - 1ms/step\n",
            "Epoch 49/100\n",
            "161/161 - 0s - loss: 0.0140 - 259ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "161/161 - 0s - loss: 0.0140 - 246ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "161/161 - 0s - loss: 0.0141 - 239ms/epoch - 1ms/step\n",
            "Epoch 52/100\n",
            "161/161 - 0s - loss: 0.0141 - 238ms/epoch - 1ms/step\n",
            "Epoch 53/100\n",
            "161/161 - 0s - loss: 0.0141 - 250ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "161/161 - 0s - loss: 0.0139 - 255ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "161/161 - 0s - loss: 0.0136 - 251ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "161/161 - 0s - loss: 0.0139 - 289ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "161/161 - 0s - loss: 0.0137 - 250ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "161/161 - 0s - loss: 0.0135 - 237ms/epoch - 1ms/step\n",
            "Epoch 59/100\n",
            "161/161 - 0s - loss: 0.0140 - 247ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "161/161 - 0s - loss: 0.0140 - 262ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "161/161 - 0s - loss: 0.0139 - 249ms/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "161/161 - 0s - loss: 0.0138 - 264ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "161/161 - 0s - loss: 0.0138 - 256ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "161/161 - 0s - loss: 0.0136 - 286ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "161/161 - 0s - loss: 0.0136 - 252ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "161/161 - 0s - loss: 0.0137 - 248ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "161/161 - 0s - loss: 0.0136 - 269ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "161/161 - 0s - loss: 0.0138 - 279ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "161/161 - 0s - loss: 0.0137 - 362ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "161/161 - 0s - loss: 0.0136 - 314ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "161/161 - 0s - loss: 0.0138 - 320ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "161/161 - 0s - loss: 0.0135 - 301ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "161/161 - 0s - loss: 0.0139 - 324ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "161/161 - 0s - loss: 0.0138 - 257ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "161/161 - 0s - loss: 0.0136 - 239ms/epoch - 1ms/step\n",
            "Epoch 76/100\n",
            "161/161 - 0s - loss: 0.0135 - 238ms/epoch - 1ms/step\n",
            "Epoch 77/100\n",
            "161/161 - 0s - loss: 0.0138 - 240ms/epoch - 1ms/step\n",
            "Epoch 78/100\n",
            "161/161 - 0s - loss: 0.0132 - 253ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "161/161 - 0s - loss: 0.0135 - 262ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "161/161 - 0s - loss: 0.0133 - 251ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "161/161 - 0s - loss: 0.0135 - 244ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "161/161 - 0s - loss: 0.0134 - 255ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "161/161 - 0s - loss: 0.0134 - 248ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "161/161 - 0s - loss: 0.0133 - 255ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "161/161 - 0s - loss: 0.0133 - 242ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "161/161 - 0s - loss: 0.0135 - 277ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "161/161 - 0s - loss: 0.0133 - 245ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "161/161 - 0s - loss: 0.0134 - 234ms/epoch - 1ms/step\n",
            "Epoch 89/100\n",
            "161/161 - 0s - loss: 0.0133 - 240ms/epoch - 1ms/step\n",
            "Epoch 90/100\n",
            "161/161 - 0s - loss: 0.0134 - 250ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "161/161 - 0s - loss: 0.0133 - 247ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "161/161 - 0s - loss: 0.0134 - 252ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "161/161 - 0s - loss: 0.0131 - 248ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "161/161 - 0s - loss: 0.0134 - 255ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "161/161 - 0s - loss: 0.0135 - 245ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "161/161 - 0s - loss: 0.0131 - 247ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "161/161 - 0s - loss: 0.0131 - 260ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "161/161 - 0s - loss: 0.0133 - 285ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "161/161 - 0s - loss: 0.0130 - 237ms/epoch - 1ms/step\n",
            "Epoch 100/100\n",
            "161/161 - 0s - loss: 0.0132 - 243ms/epoch - 2ms/step\n",
            "모든 주식에 대한 LSTM 모델 학습이 완료되었습니다.\n",
            "1/1 [==============================] - 0s 381ms/step\n",
            "1/1 [==============================] - 0s 378ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ae33afe01f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 691ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44050 (\\N{HANGUL SYLLABLE GABS}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 49885 (\\N{HANGUL SYLLABLE SIG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 50696 (\\N{HANGUL SYLLABLE YE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 52769 (\\N{HANGUL SYLLABLE CEUG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 46108 (\\N{HANGUL SYLLABLE DOEN}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48320 (\\N{HANGUL SYLLABLE BYEON}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 46041 (\\N{HANGUL SYLLABLE DONG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 49892 (\\N{HANGUL SYLLABLE SIL}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51228 (\\N{HANGUL SYLLABLE JE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48143 (\\N{HANGUL SYLLABLE MIC}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 52572 (\\N{HANGUL SYLLABLE COE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51201 (\\N{HANGUL SYLLABLE JEOG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51032 (\\N{HANGUL SYLLABLE YI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51473 (\\N{HANGUL SYLLABLE JUNG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 주식 비중:\n",
            "005930.KS: 0.18\n",
            "LPL: 0.20\n",
            "NVDA: 0.63\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "추천 주식 비중:\n",
            "005930.KS: 17.67%\n",
            "LPL: 19.67%\n",
            "NVDA: 62.66%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# 사용자로부터 보유 주식 입력 받기\n",
        "stock_list = input(\"보유하고 있는 주식의 티커 목록을 쉼표로 구분하여 입력하세요 (예: AAPL,GOOGL,MSFT): \").split(\",\")\n",
        "stock_list = [stock.strip() for stock in stock_list]\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "# 주식 데이터 가져오기\n",
        "def fetch_data(tickers):\n",
        "    data = {}\n",
        "    for ticker in tickers:\n",
        "        stock_data = yf.Ticker(ticker)\n",
        "        data[ticker] = stock_data.history(period=\"1y\")  # 최근 1년간의 데이터 가져오기\n",
        "    return data\n",
        "\n",
        "stock_data = fetch_data(stock_list)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 수익률 및 변동성 계산\n",
        "returns = {}\n",
        "for stock, data in stock_data.items():\n",
        "    prices = data['Close'].values.astype(float)\n",
        "    daily_returns = prices[1:] / prices[:-1] - 1\n",
        "    returns[stock] = daily_returns\n",
        "\n",
        "# LSTM 모델 학습을 위한 데이터 준비\n",
        "look_back = 5\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - look_back - 1):\n",
        "        a = dataset[i:(i + look_back)]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# LSTM 모델 학습\n",
        "models = {}\n",
        "for stock, daily_returns in returns.items():\n",
        "    # 데이터 정규화\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    daily_returns = scaler.fit_transform(daily_returns.reshape(-1, 1))\n",
        "\n",
        "    # 데이터 분할\n",
        "    train_size = int(len(daily_returns) * 0.67)\n",
        "    test_size = len(daily_returns) - train_size\n",
        "    train, test = daily_returns[0:train_size, :], daily_returns[train_size:len(daily_returns), :]\n",
        "\n",
        "    # LSTM에 필요한 데이터 형식으로 변환\n",
        "    X_train, Y_train = create_dataset(train, look_back)\n",
        "    X_test, Y_test = create_dataset(test, look_back)\n",
        "\n",
        "    # LSTM 모델 구성\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(X_train, Y_train, epochs=100, batch_size=1, verbose=2)\n",
        "\n",
        "    # 모델 저장\n",
        "    models[stock] = model\n",
        "\n",
        "print(\"모든 주식에 대한 LSTM 모델 학습이 완료되었습니다.\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# 각 주식의 예측된 변동성 계산\n",
        "predicted_volatilities = {}\n",
        "for stock, model in models.items():\n",
        "    last_sequence = returns[stock][-look_back:]\n",
        "    scaled_sequence = scaler.transform(last_sequence.reshape(-1, 1))\n",
        "    predicted_return = model.predict(scaled_sequence.reshape(1, look_back, 1))\n",
        "    predicted_volatility = scaler.inverse_transform(predicted_return)[0][0]\n",
        "    predicted_volatilities[stock] = predicted_volatility\n",
        "\n",
        "# 리스크 기여도를 동일하게 하는 최적의 주식 비중 계산 함수\n",
        "def risk_parity_objective(weights, volatilities):\n",
        "    # 각 주식의 리스크 기여도 계산\n",
        "    risk_contributions = [vol * weight for vol, weight in zip(volatilities, weights)]\n",
        "    total_portfolio_volatility = np.sum(risk_contributions)\n",
        "    risk_contributions = [rc / total_portfolio_volatility for rc in risk_contributions]\n",
        "\n",
        "    # 리스크 기여도 간의 편차를 최소화하는 것이 목표\n",
        "    target_risk_contribution = 1 / len(volatilities)\n",
        "    return sum([(rc - target_risk_contribution)**2 for rc in risk_contributions])\n",
        "\n",
        "# 최적화 시작\n",
        "initial_weights = [1/len(stock_list) for _ in stock_list]\n",
        "bounds = [(0, 1) for _ in stock_list]\n",
        "constraints = {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1}\n",
        "optimized = minimize(risk_parity_objective, initial_weights, args=(list(predicted_volatilities.values()),),\n",
        "                     method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n",
        "# 최적의 주식 비중 출력\n",
        "optimal_weights = optimized.x\n",
        "print(\"최적의 주식 비중:\")\n",
        "for stock, weight in zip(stock_list, optimal_weights):\n",
        "    print(f\"{stock}: {weight:.2f}\")\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "# 실제 변동성 계산\n",
        "actual_volatilities = {stock: data['Close'].pct_change().std() for stock, data in stock_data.items()}\n",
        "\n",
        "# 그래프 그리기\n",
        "stocks = list(stock_data.keys())\n",
        "predicted_vols = [predicted_volatilities[stock] for stock in stocks]\n",
        "actual_vols = [actual_volatilities[stock] for stock in stocks]\n",
        "weights = [weight for weight in optimal_weights]\n",
        "\n",
        "barWidth = 0.25\n",
        "r1 = np.arange(len(stocks))\n",
        "r2 = [x + barWidth for x in r1]\n",
        "r3 = [x + barWidth for x in r2]\n",
        "\n",
        "plt.figure(figsize=(12,7))\n",
        "\n",
        "# 바 차트 생성\n",
        "plt.bar(r1, predicted_vols, width=barWidth, color='blue', edgecolor='grey', label='예측된 변동성')\n",
        "plt.bar(r2, actual_vols, width=barWidth, color='red', edgecolor='grey', label='실제 변동성')\n",
        "plt.bar(r3, weights, width=barWidth, color='green', edgecolor='grey', label='최적의 주식 비중')\n",
        "\n",
        "# 그래프 제목 및 축 이름 설정\n",
        "plt.title('주식별 예측된 변동성, 실제 변동성 및 최적의 주식 비중', fontweight='bold')\n",
        "plt.xlabel('주식', fontweight='bold')\n",
        "plt.xticks([r + barWidth for r in range(len(stocks))], stocks)\n",
        "plt.ylabel('값', fontweight='bold')\n",
        "\n",
        "# 범례 표시\n",
        "plt.legend()\n",
        "\n",
        "# 그래프 표시\n",
        "plt.show()\n",
        "\n",
        "def recommend_weights(optimal_weights, stocks):\n",
        "    print(\"\\n추천 주식 비중:\")\n",
        "    for stock, weight in zip(stocks, optimal_weights):\n",
        "        print(f\"{stock}: {weight:.2%}\")\n",
        "\n",
        "recommend_weights(weights, stocks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(actual_volatilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qmobVf1OJDJ",
        "outputId": "b9c6092f-f67d-4ed7-fe84-0c4e7bf1f7bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'005930.KS': 0.014657872221429275, 'LPL': 0.024851936559823554, 'NVDA': 0.03394189882574205}\n"
          ]
        }
      ]
    }
  ]
}