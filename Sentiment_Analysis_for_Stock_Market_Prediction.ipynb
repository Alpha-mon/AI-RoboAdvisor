{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr3pIxq4KuU1rELYUEMvuS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alpha-mon/AI-RoboAdvisor/blob/main/Sentiment_Analysis_for_Stock_Market_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zgn2NUhqzLle"
      },
      "outputs": [],
      "source": [
        "# 뉴스 제목, 일자 크롤링\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101&date=\"\n",
        "\n",
        "# 1. User-Agent를 설정\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# 시작 날짜와 종료 날짜 설정\n",
        "start_date = datetime.datetime.now() - datetime.timedelta(days=30)\n",
        "end_date = datetime.datetime.now() - datetime.timedelta(days=5)\n",
        "\n",
        "current_date = start_date\n",
        "\n",
        "news_data = []\n",
        "\n",
        "while current_date <= end_date:\n",
        "    # 2. 요청을 보낼 때 headers 추가\n",
        "    response = requests.get(base_url + current_date.strftime('%Y%m%d'), headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    for item in soup.select(\".cluster_text a\"):\n",
        "        title = item.text.strip()\n",
        "        if item.attrs[\"href\"].startswith(\"http\"):\n",
        "            news_url = item.attrs[\"href\"]\n",
        "        else:\n",
        "            news_url = \"https:\" + item.attrs[\"href\"]\n",
        "\n",
        "        detail_response = requests.get(news_url, headers=headers)  # headers 추가\n",
        "        detail_soup = BeautifulSoup(detail_response.text, 'html.parser')\n",
        "        date_element = detail_soup.select_one(\"span.media_end_head_info_datestamp_time\")\n",
        "        date = date_element.attrs[\"data-date-time\"].split()[0]\n",
        "\n",
        "        news_data.append({\n",
        "            'title': title,\n",
        "            'date': date\n",
        "        })\n",
        "\n",
        "        # 요청 간에 약간의 지연을 두어 IP 차단을 피하기\n",
        "        time.sleep(1.5)\n",
        "\n",
        "    # 다음 날짜로 이동\n",
        "    current_date += datetime.timedelta(days=1)\n",
        "\n",
        "# 뉴스 데이터를 날짜 순으로 정렬\n",
        "news_data_sorted = sorted(news_data, key=lambda x: x['date'])\n",
        "\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "news_df = pd.DataFrame(news_data_sorted, columns=['date', 'title'])\n",
        "\n",
        "# 시작 날짜와 종료 날짜를 문자열로 변환\n",
        "start_date_str = start_date.strftime('%Y-%m-%d')\n",
        "end_date_str = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "# 원하는 날짜 범위만 선택\n",
        "news_df = news_df[(news_df['date'] >= start_date_str) & (news_df['date'] <= end_date_str)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXlG49V01JRX",
        "outputId": "b552735f-15e7-466b-e729-199766a8e7d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 크롤링한 뉴스 제목 명사 추출\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "# Okt 객체 초기화\n",
        "okt = Okt()\n",
        "\n",
        "# 제목에서 명사만 추출하는 함수\n",
        "def extract_nouns(title):\n",
        "    return ', '.join(okt.nouns(title))\n",
        "\n",
        "# 'title' 열의 각 제목에 대하여 명사만 추출\n",
        "news_df['nouns'] = news_df['title'].apply(extract_nouns)\n",
        "\n",
        "print(news_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsncbVAf0C4p",
        "outputId": "ef32c262-f04e-4098-f53d-ab35c06158e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          date                                          title  \\\n",
            "5   2023-09-19                          삼성전자, 3주만에 다시 '6만전자'로   \n",
            "6   2023-09-19                          삼성전자, 3주만에 다시 '6만전자'로   \n",
            "7   2023-09-19                       수요와 균형 이루는 주택공급 확대 정책 기대   \n",
            "8   2023-09-20                  주택구입자 3분의1이 받은 특례보금자리론…축소 파장은   \n",
            "9   2023-09-27                    도생·오피스텔에 기금 지원…공급부족 해소 도움될까   \n",
            "10  2023-09-27                    사라 버튼 떠나는 알렉산더 맥퀸, 후임 누가 될까   \n",
            "11  2023-09-27                             이더리움 NFT가 지갑이 된다고?   \n",
            "12  2023-10-03  ‘월클 美모’ 송혜교‧수지, 300만원 vs 1000만원 ‘여신 드레스룩’ 승자는   \n",
            "13  2023-10-03                    [데스크칼럼]반쪽 주택대책 안되려면 ‘실행’뿐이다   \n",
            "14  2023-10-04                        디폴트옵션 완전정복…당신도 연금부자 됩니다   \n",
            "15  2023-10-05                      IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "16  2023-10-05               \"에코프로 욕하려면 80만원 내세요\"…확 달라진 '종토방'   \n",
            "17  2023-10-05                      IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "18  2023-10-06                    80~1000만원대까지…시선강탈 레드카펫 ★드레스   \n",
            "19  2023-10-06                \"모두 백인 남성이네\" 명품기업 케링그룹, 욕 먹는 이유   \n",
            "20  2023-10-06                     빗썸 수수료 무료, 830 프로젝트 덕분이라고?   \n",
            "21  2023-10-11                    삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "22  2023-10-11                    삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "23  2023-10-11                            [데스크칼럼]먹거리 물가와 기후위기   \n",
            "24  2023-10-11             \"억눌렸던 욕구 폭발\"…뉴진스 '팝업스토어' 대박 이유 있었다   \n",
            "25  2023-10-11              '목욕탕 슬리퍼'가 11조원 회사로…200년을 버틴 버켄스탁   \n",
            "26  2023-10-11                뉴:홈, 당첨일 다르면 중복청약 OK…거주 의무도 꼼꼼히   \n",
            "27  2023-10-11                   마곡 3억·하남 4억대 ‘뉴홈’ 3300가구 풀린다   \n",
            "28  2023-10-11                      같이 오르내리던 매매·전세가, 이제 동행 끝?   \n",
            "29  2023-10-11                고조되는 이-팔 전쟁 우려, 코인은 정말 위기에 강한가?   \n",
            "30  2023-10-12                  \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "31  2023-10-12                  \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "32  2023-10-12              \"클수록 좋다\" SUV 판매 1위는 쏘렌토…파업 리스크 변수   \n",
            "33  2023-10-12                   지방소멸 해법 떠오른 다주택자 규제…패러다임 바뀌나   \n",
            "34  2023-10-12                 청계천 떠난 '작은 공장'이 말하는 떠나야만 했던 이유   \n",
            "35  2023-10-13          \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "36  2023-10-13                          포르셰 뽑은 30대, 인천서 확 늘었다   \n",
            "37  2023-10-13       뉴욕증시, 예상 웃돈 CPI·국채금리 상승에 일제 하락…테슬라 1.5%↓   \n",
            "38  2023-10-13          \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "39  2023-10-13                 한국 AI 경쟁력 세계 6위?…하위 굳히는 핵심 영역은   \n",
            "40  2023-10-13                    '미 국채가 안 팔린다'…증시 흔든 채권금리 급등   \n",
            "41  2023-10-13                코스피, 美 CPI 부담에 1% 하락…2456.15 마감   \n",
            "42  2023-10-13              '엔씨소프트 vs 카카오' 국민 밉상주 투표 열렸다…결과는?   \n",
            "43  2023-10-13                  550억에 인수하더니…'마흔살' KFC의 놀라운 변신   \n",
            "44  2023-10-13                 좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "45  2023-10-13                       분양가 너무 비쌌나…서울서 미분양 나온 까닭   \n",
            "\n",
            "                                    nouns  \n",
            "5                        삼성, 전자, 주, 다시, 로  \n",
            "6                        삼성, 전자, 주, 다시, 로  \n",
            "7              수요, 균형, 주택, 공급, 확대, 정책, 기대  \n",
            "8          주택, 구입, 이, 특례, 보금자리, 론, 축소, 파장  \n",
            "9        도생, 오피스텔, 기금, 지원, 공급, 부족, 해소, 도움  \n",
            "10               사라, 버튼, 알렉산더, 맥퀸, 후임, 누가  \n",
            "11                              더, 리움, 지갑  \n",
            "12             월, 모, 송혜교, 수지, 여신, 드레스, 승자  \n",
            "13             데스크, 칼럼, 반쪽, 주택, 대책, 실행, 뿐  \n",
            "14            디폴트, 옵션, 완전, 정복, 당신, 연금, 부자  \n",
            "15                   두산, 로보틱스, 상장, 첫날, 따블  \n",
            "16                에코, 프로, 욕, 내세, 확, 종, 토방  \n",
            "17                   두산, 로보틱스, 상장, 첫날, 따블  \n",
            "18                      시선, 강탈, 레드카펫, 드레스  \n",
            "19      모두, 백인, 남성, 명품, 기업, 케링, 그룹, 욕, 이유  \n",
            "20                  빗썸, 수수료, 무료, 프로젝트, 덕분  \n",
            "21           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "22           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "23               데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "24           욕구, 폭발, 뉴진스, 팝업, 스토어, 대박, 이유  \n",
            "25                     목욕탕, 슬리퍼, 회사, 버켄스탁  \n",
            "26            뉴, 홈, 당첨, 일, 중복, 청약, 거주, 의무  \n",
            "27                         마곡, 하남, 뉴홈, 가구  \n",
            "28                      매매, 전세, 이제, 동행, 끝  \n",
            "29           고조, 이, 팔, 전쟁, 우려, 코인, 정말, 위기  \n",
            "30                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "31                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "32                판매, 위, 쏘렌토, 파업, 리스크, 변수  \n",
            "33               지방, 소멸, 해법, 주택, 규제, 패러다임  \n",
            "34                      청계천, 공장, 이, 말, 이유  \n",
            "35          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "36                             포르셰, 인천, 확  \n",
            "37  뉴욕증시, 예상, 웃돈, 국채, 금리, 상승, 일제, 하락, 테슬라  \n",
            "38          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "39             한국, 경쟁력, 세계, 위, 하위, 핵심, 영역  \n",
            "40              국채, 안, 린다, 증시, 채권, 금리, 급등  \n",
            "41                        코스피, 부담, 하락, 마감  \n",
            "42             엔씨소프트, 카카오, 국민, 상주, 투표, 결과  \n",
            "43                           인수, 살, 의, 변신  \n",
            "44             좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "45                         분양, 서울, 미분, 까닭  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코스피 등락율 - 뉴스\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def get_kospi_closing_prices():\n",
        "    url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSPI\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    kospi_closings = []\n",
        "\n",
        "    for i in range(1, 7):\n",
        "        response = requests.get(url + f\"&page={i}\", headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        dates = soup.select(\".date\")\n",
        "        closings = soup.select(\".number_1\")\n",
        "\n",
        "        for d, c in zip(dates, closings[::4]):  # 종가만 가져오기 위해 slicing 사용\n",
        "            kospi_closings.append([d.text.strip(), float(c.text.replace(',', ''))])\n",
        "\n",
        "    return kospi_closings\n",
        "\n",
        "kospi_data = get_kospi_closing_prices()\n",
        "df = pd.DataFrame(kospi_data, columns=[\"Date\", \"Closing\"])\n",
        "\n",
        "# Shift를 사용해 다음 날짜의 종가를 가져와서 현재 날짜와 비교\n",
        "# 예: 10월 9일 종가보다 10월 10일 종가가 더 높다면 10월 9일 등락율 1이 됨\n",
        "\n",
        "df[\"Up/Down\"] = (df[\"Closing\"].shift(1) > df[\"Closing\"]).astype(int)\n",
        "\n",
        "# 날짜 기준으로 최근 30일의 데이터를 가져온 후, 정렬\n",
        "df = df.sort_values(by=\"Date\").tail(30).reset_index(drop=True)\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%Y.%m.%d').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "print(df)\n",
        "\n",
        "merged_df = pd.merge(news_df, df, left_on='date', right_on='Date', how='inner')\n",
        "merged_df = merged_df[['date', 'Up/Down', 'title', 'nouns']]\n",
        "print(merged_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFLDnMan0OVg",
        "outputId": "6586726b-a400-4fce-f152-472c004f492b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date  Closing  Up/Down\n",
            "0   2023-08-31  2556.27        1\n",
            "1   2023-09-01  2563.71        1\n",
            "2   2023-09-04  2584.55        0\n",
            "3   2023-09-05  2582.18        0\n",
            "4   2023-09-06  2563.34        0\n",
            "5   2023-09-07  2548.26        0\n",
            "6   2023-09-08  2547.68        1\n",
            "7   2023-09-11  2556.88        0\n",
            "8   2023-09-12  2536.58        0\n",
            "9   2023-09-13  2534.70        1\n",
            "10  2023-09-14  2572.89        1\n",
            "11  2023-09-15  2601.28        0\n",
            "12  2023-09-18  2574.72        0\n",
            "13  2023-09-19  2559.21        1\n",
            "14  2023-09-20  2559.74        0\n",
            "15  2023-09-21  2514.97        0\n",
            "16  2023-09-22  2508.13        0\n",
            "17  2023-09-25  2495.76        0\n",
            "18  2023-09-26  2462.97        1\n",
            "19  2023-09-27  2465.07        0\n",
            "20  2023-10-04  2405.69        0\n",
            "21  2023-10-05  2403.60        1\n",
            "22  2023-10-06  2408.73        0\n",
            "23  2023-10-10  2402.58        1\n",
            "24  2023-10-11  2450.08        1\n",
            "25  2023-10-12  2479.82        0\n",
            "26  2023-10-13  2456.15        0\n",
            "27  2023-10-16  2436.24        1\n",
            "28  2023-10-17  2460.17        1\n",
            "29  2023-10-18  2462.60        0\n",
            "          date  Up/Down                                     title  \\\n",
            "0   2023-09-19        1                     삼성전자, 3주만에 다시 '6만전자'로   \n",
            "1   2023-09-19        1                     삼성전자, 3주만에 다시 '6만전자'로   \n",
            "2   2023-09-19        1                  수요와 균형 이루는 주택공급 확대 정책 기대   \n",
            "3   2023-09-20        0             주택구입자 3분의1이 받은 특례보금자리론…축소 파장은   \n",
            "4   2023-09-27        0               도생·오피스텔에 기금 지원…공급부족 해소 도움될까   \n",
            "5   2023-09-27        0               사라 버튼 떠나는 알렉산더 맥퀸, 후임 누가 될까   \n",
            "6   2023-09-27        0                        이더리움 NFT가 지갑이 된다고?   \n",
            "7   2023-10-04        0                   디폴트옵션 완전정복…당신도 연금부자 됩니다   \n",
            "8   2023-10-05        1                 IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "9   2023-10-05        1          \"에코프로 욕하려면 80만원 내세요\"…확 달라진 '종토방'   \n",
            "10  2023-10-05        1                 IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "11  2023-10-06        0               80~1000만원대까지…시선강탈 레드카펫 ★드레스   \n",
            "12  2023-10-06        0           \"모두 백인 남성이네\" 명품기업 케링그룹, 욕 먹는 이유   \n",
            "13  2023-10-06        0                빗썸 수수료 무료, 830 프로젝트 덕분이라고?   \n",
            "14  2023-10-11        1               삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "15  2023-10-11        1               삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "16  2023-10-11        1                       [데스크칼럼]먹거리 물가와 기후위기   \n",
            "17  2023-10-11        1        \"억눌렸던 욕구 폭발\"…뉴진스 '팝업스토어' 대박 이유 있었다   \n",
            "18  2023-10-11        1         '목욕탕 슬리퍼'가 11조원 회사로…200년을 버틴 버켄스탁   \n",
            "19  2023-10-11        1           뉴:홈, 당첨일 다르면 중복청약 OK…거주 의무도 꼼꼼히   \n",
            "20  2023-10-11        1              마곡 3억·하남 4억대 ‘뉴홈’ 3300가구 풀린다   \n",
            "21  2023-10-11        1                 같이 오르내리던 매매·전세가, 이제 동행 끝?   \n",
            "22  2023-10-11        1           고조되는 이-팔 전쟁 우려, 코인은 정말 위기에 강한가?   \n",
            "23  2023-10-12        0             \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "24  2023-10-12        0             \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "25  2023-10-12        0         \"클수록 좋다\" SUV 판매 1위는 쏘렌토…파업 리스크 변수   \n",
            "26  2023-10-12        0              지방소멸 해법 떠오른 다주택자 규제…패러다임 바뀌나   \n",
            "27  2023-10-12        0            청계천 떠난 '작은 공장'이 말하는 떠나야만 했던 이유   \n",
            "28  2023-10-13        0     \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "29  2023-10-13        0                     포르셰 뽑은 30대, 인천서 확 늘었다   \n",
            "30  2023-10-13        0  뉴욕증시, 예상 웃돈 CPI·국채금리 상승에 일제 하락…테슬라 1.5%↓   \n",
            "31  2023-10-13        0     \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "32  2023-10-13        0            한국 AI 경쟁력 세계 6위?…하위 굳히는 핵심 영역은   \n",
            "33  2023-10-13        0               '미 국채가 안 팔린다'…증시 흔든 채권금리 급등   \n",
            "34  2023-10-13        0           코스피, 美 CPI 부담에 1% 하락…2456.15 마감   \n",
            "35  2023-10-13        0         '엔씨소프트 vs 카카오' 국민 밉상주 투표 열렸다…결과는?   \n",
            "36  2023-10-13        0             550억에 인수하더니…'마흔살' KFC의 놀라운 변신   \n",
            "37  2023-10-13        0            좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "38  2023-10-13        0                  분양가 너무 비쌌나…서울서 미분양 나온 까닭   \n",
            "\n",
            "                                    nouns  \n",
            "0                        삼성, 전자, 주, 다시, 로  \n",
            "1                        삼성, 전자, 주, 다시, 로  \n",
            "2              수요, 균형, 주택, 공급, 확대, 정책, 기대  \n",
            "3          주택, 구입, 이, 특례, 보금자리, 론, 축소, 파장  \n",
            "4        도생, 오피스텔, 기금, 지원, 공급, 부족, 해소, 도움  \n",
            "5                사라, 버튼, 알렉산더, 맥퀸, 후임, 누가  \n",
            "6                               더, 리움, 지갑  \n",
            "7             디폴트, 옵션, 완전, 정복, 당신, 연금, 부자  \n",
            "8                    두산, 로보틱스, 상장, 첫날, 따블  \n",
            "9                 에코, 프로, 욕, 내세, 확, 종, 토방  \n",
            "10                   두산, 로보틱스, 상장, 첫날, 따블  \n",
            "11                      시선, 강탈, 레드카펫, 드레스  \n",
            "12      모두, 백인, 남성, 명품, 기업, 케링, 그룹, 욕, 이유  \n",
            "13                  빗썸, 수수료, 무료, 프로젝트, 덕분  \n",
            "14           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "15           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "16               데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "17           욕구, 폭발, 뉴진스, 팝업, 스토어, 대박, 이유  \n",
            "18                     목욕탕, 슬리퍼, 회사, 버켄스탁  \n",
            "19            뉴, 홈, 당첨, 일, 중복, 청약, 거주, 의무  \n",
            "20                         마곡, 하남, 뉴홈, 가구  \n",
            "21                      매매, 전세, 이제, 동행, 끝  \n",
            "22           고조, 이, 팔, 전쟁, 우려, 코인, 정말, 위기  \n",
            "23                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "24                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "25                판매, 위, 쏘렌토, 파업, 리스크, 변수  \n",
            "26               지방, 소멸, 해법, 주택, 규제, 패러다임  \n",
            "27                      청계천, 공장, 이, 말, 이유  \n",
            "28          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "29                             포르셰, 인천, 확  \n",
            "30  뉴욕증시, 예상, 웃돈, 국채, 금리, 상승, 일제, 하락, 테슬라  \n",
            "31          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "32             한국, 경쟁력, 세계, 위, 하위, 핵심, 영역  \n",
            "33              국채, 안, 린다, 증시, 채권, 금리, 급등  \n",
            "34                        코스피, 부담, 하락, 마감  \n",
            "35             엔씨소프트, 카카오, 국민, 상주, 투표, 결과  \n",
            "36                           인수, 살, 의, 변신  \n",
            "37             좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "38                         분양, 서울, 미분, 까닭  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 점수 초기화 및 개수\n",
        "# 한 글자 제외 -> 두 글자 이상 단어\n",
        "\n",
        "# 'nouns' 칼럼의 값을 문자열로 변환\n",
        "df['nouns'] = merged_df['nouns'].astype(str)\n",
        "df = df.dropna(subset=['nouns'])\n",
        "\n",
        "# 'filtered_nouns' 컬럼 생성\n",
        "merged_df['filtered_nouns'] = merged_df['nouns'].apply(lambda x: [word for word in x.split(', ') if len(word) > 1])\n",
        "\n",
        "# 단어 점수 초기화\n",
        "word_scores = {word: 0 for word_list in merged_df['filtered_nouns'] for word in word_list}\n",
        "print(word_scores)\n",
        "\n",
        "# 단어 빈도수 계산\n",
        "from collections import Counter\n",
        "word_counts = Counter(word for word_list in merged_df['filtered_nouns'] for word in word_list)\n",
        "\n",
        "# 결과 출력\n",
        "for word, count in word_counts.items():\n",
        "    print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe-vTxdr0yRi",
        "outputId": "86020655-c92d-47ca-a8eb-9b116b428c74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'삼성': 0, '전자': 0, '다시': 0, '수요': 0, '균형': 0, '주택': 0, '공급': 0, '확대': 0, '정책': 0, '기대': 0, '구입': 0, '특례': 0, '보금자리': 0, '축소': 0, '파장': 0, '도생': 0, '오피스텔': 0, '기금': 0, '지원': 0, '부족': 0, '해소': 0, '도움': 0, '사라': 0, '버튼': 0, '알렉산더': 0, '맥퀸': 0, '후임': 0, '누가': 0, '리움': 0, '지갑': 0, '디폴트': 0, '옵션': 0, '완전': 0, '정복': 0, '당신': 0, '연금': 0, '부자': 0, '두산': 0, '로보틱스': 0, '상장': 0, '첫날': 0, '따블': 0, '에코': 0, '프로': 0, '내세': 0, '토방': 0, '시선': 0, '강탈': 0, '레드카펫': 0, '드레스': 0, '모두': 0, '백인': 0, '남성': 0, '명품': 0, '기업': 0, '케링': 0, '그룹': 0, '이유': 0, '빗썸': 0, '수수료': 0, '무료': 0, '프로젝트': 0, '덕분': 0, '단위': 0, '영업': 0, '복귀': 0, '강세': 0, '데스크': 0, '칼럼': 0, '먹거리': 0, '물가': 0, '기후': 0, '위기': 0, '욕구': 0, '폭발': 0, '뉴진스': 0, '팝업': 0, '스토어': 0, '대박': 0, '목욕탕': 0, '슬리퍼': 0, '회사': 0, '버켄스탁': 0, '당첨': 0, '중복': 0, '청약': 0, '거주': 0, '의무': 0, '마곡': 0, '하남': 0, '뉴홈': 0, '가구': 0, '매매': 0, '전세': 0, '이제': 0, '동행': 0, '고조': 0, '전쟁': 0, '우려': 0, '코인': 0, '정말': 0, '계획': 0, '최태원': 0, '구상': 0, '후계': 0, '구도': 0, '판매': 0, '쏘렌토': 0, '파업': 0, '리스크': 0, '변수': 0, '지방': 0, '소멸': 0, '해법': 0, '규제': 0, '패러다임': 0, '청계천': 0, '공장': 0, '땡큐': 0, '환호': 0, '포르셰': 0, '인천': 0, '뉴욕증시': 0, '예상': 0, '웃돈': 0, '국채': 0, '금리': 0, '상승': 0, '일제': 0, '하락': 0, '테슬라': 0, '한국': 0, '경쟁력': 0, '세계': 0, '하위': 0, '핵심': 0, '영역': 0, '린다': 0, '증시': 0, '채권': 0, '급등': 0, '코스피': 0, '부담': 0, '마감': 0, '엔씨소프트': 0, '카카오': 0, '국민': 0, '상주': 0, '투표': 0, '결과': 0, '인수': 0, '변신': 0, '좀처럼': 0, '고물': 0, '연내': 0, '추가': 0, '인상': 0, '분양': 0, '서울': 0, '미분': 0, '까닭': 0}\n",
            "삼성: 4\n",
            "전자: 4\n",
            "다시: 2\n",
            "수요: 1\n",
            "균형: 1\n",
            "주택: 3\n",
            "공급: 2\n",
            "확대: 1\n",
            "정책: 1\n",
            "기대: 1\n",
            "구입: 1\n",
            "특례: 1\n",
            "보금자리: 1\n",
            "축소: 1\n",
            "파장: 1\n",
            "도생: 1\n",
            "오피스텔: 1\n",
            "기금: 1\n",
            "지원: 1\n",
            "부족: 1\n",
            "해소: 1\n",
            "도움: 1\n",
            "사라: 1\n",
            "버튼: 1\n",
            "알렉산더: 1\n",
            "맥퀸: 1\n",
            "후임: 1\n",
            "누가: 1\n",
            "리움: 1\n",
            "지갑: 1\n",
            "디폴트: 1\n",
            "옵션: 1\n",
            "완전: 1\n",
            "정복: 1\n",
            "당신: 1\n",
            "연금: 1\n",
            "부자: 1\n",
            "두산: 2\n",
            "로보틱스: 2\n",
            "상장: 2\n",
            "첫날: 2\n",
            "따블: 2\n",
            "에코: 1\n",
            "프로: 1\n",
            "내세: 1\n",
            "토방: 1\n",
            "시선: 1\n",
            "강탈: 1\n",
            "레드카펫: 1\n",
            "드레스: 1\n",
            "모두: 3\n",
            "백인: 1\n",
            "남성: 1\n",
            "명품: 1\n",
            "기업: 1\n",
            "케링: 1\n",
            "그룹: 1\n",
            "이유: 3\n",
            "빗썸: 1\n",
            "수수료: 1\n",
            "무료: 1\n",
            "프로젝트: 1\n",
            "덕분: 1\n",
            "단위: 2\n",
            "영업: 4\n",
            "복귀: 2\n",
            "강세: 2\n",
            "데스크: 1\n",
            "칼럼: 1\n",
            "먹거리: 1\n",
            "물가: 1\n",
            "기후: 1\n",
            "위기: 2\n",
            "욕구: 1\n",
            "폭발: 1\n",
            "뉴진스: 1\n",
            "팝업: 1\n",
            "스토어: 1\n",
            "대박: 1\n",
            "목욕탕: 1\n",
            "슬리퍼: 1\n",
            "회사: 1\n",
            "버켄스탁: 1\n",
            "당첨: 1\n",
            "중복: 1\n",
            "청약: 1\n",
            "거주: 1\n",
            "의무: 1\n",
            "마곡: 1\n",
            "하남: 1\n",
            "뉴홈: 1\n",
            "가구: 1\n",
            "매매: 1\n",
            "전세: 1\n",
            "이제: 1\n",
            "동행: 1\n",
            "고조: 1\n",
            "전쟁: 1\n",
            "우려: 1\n",
            "코인: 1\n",
            "정말: 1\n",
            "계획: 2\n",
            "최태원: 2\n",
            "구상: 2\n",
            "후계: 2\n",
            "구도: 2\n",
            "판매: 1\n",
            "쏘렌토: 1\n",
            "파업: 1\n",
            "리스크: 1\n",
            "변수: 1\n",
            "지방: 1\n",
            "소멸: 1\n",
            "해법: 1\n",
            "규제: 1\n",
            "패러다임: 1\n",
            "청계천: 1\n",
            "공장: 1\n",
            "땡큐: 2\n",
            "환호: 2\n",
            "포르셰: 1\n",
            "인천: 1\n",
            "뉴욕증시: 1\n",
            "예상: 1\n",
            "웃돈: 1\n",
            "국채: 2\n",
            "금리: 3\n",
            "상승: 1\n",
            "일제: 1\n",
            "하락: 2\n",
            "테슬라: 1\n",
            "한국: 1\n",
            "경쟁력: 1\n",
            "세계: 1\n",
            "하위: 1\n",
            "핵심: 1\n",
            "영역: 1\n",
            "린다: 1\n",
            "증시: 1\n",
            "채권: 1\n",
            "급등: 1\n",
            "코스피: 1\n",
            "부담: 1\n",
            "마감: 1\n",
            "엔씨소프트: 1\n",
            "카카오: 1\n",
            "국민: 1\n",
            "상주: 1\n",
            "투표: 1\n",
            "결과: 1\n",
            "인수: 1\n",
            "변신: 1\n",
            "좀처럼: 1\n",
            "고물: 1\n",
            "연내: 1\n",
            "추가: 1\n",
            "인상: 1\n",
            "분양: 1\n",
            "서울: 1\n",
            "미분: 1\n",
            "까닭: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 점수 부여\n",
        "\n",
        "# 전체 단어 개수 출력\n",
        "total_words = sum(word_counts.values())\n",
        "print(f\"\\nTotal number of words: {total_words}\")\n",
        "\n",
        "# Up/Down 값이 1인 데이터에서 포함된 단어의 리스트\n",
        "up = []\n",
        "for nouns in merged_df[merged_df['Up/Down'] == 1]['filtered_nouns']:\n",
        "    up.extend(nouns)\n",
        "\n",
        "# Up/Down 값이 0인 데이터에서 포함된 단어의 리스트\n",
        "down = []\n",
        "for nouns in merged_df[merged_df['Up/Down'] == 0]['filtered_nouns']:\n",
        "    down.extend(nouns)\n",
        "\n",
        "print(\"up :\", len(up))\n",
        "print(\"down :\", len(down))\n",
        "\n",
        "# 상승 비율과 하락 비율 계산\n",
        "total_words = len(up) + len(down)\n",
        "up_ratio = len(up) / total_words\n",
        "down_ratio = len(down) / total_words\n",
        "\n",
        "# 단어 점수 초기화\n",
        "word_scores = {word: 0 for word in word_scores.keys()}  # 기존의 word_scores 딕셔너리 사용\n",
        "\n",
        "# Up(1) 데이터의 단어들에 대해서 하락 비율을 더해주기\n",
        "for word in up:\n",
        "    if word in word_scores:\n",
        "        word_scores[word] += down_ratio\n",
        "\n",
        "# Down(0) 데이터의 단어들에 대해서 상승 비율을 차감해주기\n",
        "for word in down:\n",
        "    if word in word_scores:\n",
        "        word_scores[word] -= up_ratio\n",
        "\n",
        "# 결과 확인\n",
        "print(word_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QZ8ivkG096w",
        "outputId": "5ddbba72-dbcb-4a91-f7b6-9cf40495caee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of words: 198\n",
            "up : 75\n",
            "down : 123\n",
            "{'삼성': 2.484848484848485, '전자': 2.484848484848485, '다시': 1.2424242424242424, '수요': 0.6212121212121212, '균형': 0.6212121212121212, '주택': -0.13636363636363635, '공급': 0.24242424242424243, '확대': 0.6212121212121212, '정책': 0.6212121212121212, '기대': 0.6212121212121212, '구입': -0.3787878787878788, '특례': -0.3787878787878788, '보금자리': -0.3787878787878788, '축소': -0.3787878787878788, '파장': -0.3787878787878788, '도생': -0.3787878787878788, '오피스텔': -0.3787878787878788, '기금': -0.3787878787878788, '지원': -0.3787878787878788, '부족': -0.3787878787878788, '해소': -0.3787878787878788, '도움': -0.3787878787878788, '사라': -0.3787878787878788, '버튼': -0.3787878787878788, '알렉산더': -0.3787878787878788, '맥퀸': -0.3787878787878788, '후임': -0.3787878787878788, '누가': -0.3787878787878788, '리움': -0.3787878787878788, '지갑': -0.3787878787878788, '디폴트': -0.3787878787878788, '옵션': -0.3787878787878788, '완전': -0.3787878787878788, '정복': -0.3787878787878788, '당신': -0.3787878787878788, '연금': -0.3787878787878788, '부자': -0.3787878787878788, '두산': 1.2424242424242424, '로보틱스': 1.2424242424242424, '상장': 1.2424242424242424, '첫날': 1.2424242424242424, '따블': 1.2424242424242424, '에코': 0.6212121212121212, '프로': 0.6212121212121212, '내세': 0.6212121212121212, '토방': 0.6212121212121212, '시선': -0.3787878787878788, '강탈': -0.3787878787878788, '레드카펫': -0.3787878787878788, '드레스': -0.3787878787878788, '모두': -1.1363636363636362, '백인': -0.3787878787878788, '남성': -0.3787878787878788, '명품': -0.3787878787878788, '기업': -0.3787878787878788, '케링': -0.3787878787878788, '그룹': -0.3787878787878788, '이유': -0.13636363636363635, '빗썸': -0.3787878787878788, '수수료': -0.3787878787878788, '무료': -0.3787878787878788, '프로젝트': -0.3787878787878788, '덕분': -0.3787878787878788, '단위': 1.2424242424242424, '영업': 0.48484848484848486, '복귀': 1.2424242424242424, '강세': 1.2424242424242424, '데스크': 0.6212121212121212, '칼럼': 0.6212121212121212, '먹거리': 0.6212121212121212, '물가': 0.6212121212121212, '기후': 0.6212121212121212, '위기': 1.2424242424242424, '욕구': 0.6212121212121212, '폭발': 0.6212121212121212, '뉴진스': 0.6212121212121212, '팝업': 0.6212121212121212, '스토어': 0.6212121212121212, '대박': 0.6212121212121212, '목욕탕': 0.6212121212121212, '슬리퍼': 0.6212121212121212, '회사': 0.6212121212121212, '버켄스탁': 0.6212121212121212, '당첨': 0.6212121212121212, '중복': 0.6212121212121212, '청약': 0.6212121212121212, '거주': 0.6212121212121212, '의무': 0.6212121212121212, '마곡': 0.6212121212121212, '하남': 0.6212121212121212, '뉴홈': 0.6212121212121212, '가구': 0.6212121212121212, '매매': 0.6212121212121212, '전세': 0.6212121212121212, '이제': 0.6212121212121212, '동행': 0.6212121212121212, '고조': 0.6212121212121212, '전쟁': 0.6212121212121212, '우려': 0.6212121212121212, '코인': 0.6212121212121212, '정말': 0.6212121212121212, '계획': -0.7575757575757576, '최태원': -0.7575757575757576, '구상': -0.7575757575757576, '후계': -0.7575757575757576, '구도': -0.7575757575757576, '판매': -0.3787878787878788, '쏘렌토': -0.3787878787878788, '파업': -0.3787878787878788, '리스크': -0.3787878787878788, '변수': -0.3787878787878788, '지방': -0.3787878787878788, '소멸': -0.3787878787878788, '해법': -0.3787878787878788, '규제': -0.3787878787878788, '패러다임': -0.3787878787878788, '청계천': -0.3787878787878788, '공장': -0.3787878787878788, '땡큐': -0.7575757575757576, '환호': -0.7575757575757576, '포르셰': -0.3787878787878788, '인천': -0.3787878787878788, '뉴욕증시': -0.3787878787878788, '예상': -0.3787878787878788, '웃돈': -0.3787878787878788, '국채': -0.7575757575757576, '금리': -1.1363636363636362, '상승': -0.3787878787878788, '일제': -0.3787878787878788, '하락': -0.7575757575757576, '테슬라': -0.3787878787878788, '한국': -0.3787878787878788, '경쟁력': -0.3787878787878788, '세계': -0.3787878787878788, '하위': -0.3787878787878788, '핵심': -0.3787878787878788, '영역': -0.3787878787878788, '린다': -0.3787878787878788, '증시': -0.3787878787878788, '채권': -0.3787878787878788, '급등': -0.3787878787878788, '코스피': -0.3787878787878788, '부담': -0.3787878787878788, '마감': -0.3787878787878788, '엔씨소프트': -0.3787878787878788, '카카오': -0.3787878787878788, '국민': -0.3787878787878788, '상주': -0.3787878787878788, '투표': -0.3787878787878788, '결과': -0.3787878787878788, '인수': -0.3787878787878788, '변신': -0.3787878787878788, '좀처럼': -0.3787878787878788, '고물': -0.3787878787878788, '연내': -0.3787878787878788, '추가': -0.3787878787878788, '인상': -0.3787878787878788, '분양': -0.3787878787878788, '서울': -0.3787878787878788, '미분': -0.3787878787878788, '까닭': -0.3787878787878788}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 감성 사전 완료\n",
        "\n",
        "total = []\n",
        "for nouns in merged_df['filtered_nouns']:\n",
        "    sent_score = 0\n",
        "    for noun in nouns:\n",
        "        if noun in word_scores:\n",
        "            sent_score += word_scores[noun]\n",
        "\n",
        "    # 해당 뉴스 제목에 포함된 단어의 수로 나누어 평균 점수를 계산\n",
        "    avg_sent_score = sent_score / len(nouns) if nouns else 0  # 단어가 없는 경우 0으로 처리\n",
        "    total.append(avg_sent_score)\n",
        "\n",
        "merged_df['sent_score'] = total\n",
        "\n",
        "# 감성사전의 평균 점수 계산\n",
        "\n",
        "sent_mean = sum(word_scores.values()) / len(word_scores)\n",
        "print('감성 사전 평균 점수 : ',sent_mean)\n",
        "\n",
        "# 감성 점수 계산\n",
        "def calculate_sentiment_score(noun_list):\n",
        "    score = 0\n",
        "    for noun in noun_list:\n",
        "        if noun in word_scores:\n",
        "            score += word_scores[noun]\n",
        "    return score / (len(noun_list) if len(noun_list) != 0 else 1)\n",
        "\n",
        "merged_df['sent_score'] = merged_df['filtered_nouns'].apply(calculate_sentiment_score)\n",
        "\n",
        "# 평균 점수를 기준으로 라벨링\n",
        "merged_df['sent_label'] = merged_df['sent_score'].apply(lambda x: 1 if x > sent_mean else 0)\n",
        "\n",
        "\n",
        "\n",
        "result_df = merged_df[['date', 'Up/Down', 'sent_score', 'sent_label', 'title', 'nouns']]\n",
        "print(result_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqxqymCI2F5A",
        "outputId": "d41db634-1acc-47c7-cbe5-dcda71c7dfc9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "감성 사전 평균 점수 :  -8.61974398000898e-17\n",
            "          date  Up/Down  sent_score  sent_label  \\\n",
            "0   2023-09-19        1    2.070707           1   \n",
            "1   2023-09-19        1    2.070707           1   \n",
            "2   2023-09-19        1    0.458874           1   \n",
            "3   2023-09-20        0   -0.338384           0   \n",
            "4   2023-09-27        0   -0.301136           0   \n",
            "5   2023-09-27        0   -0.378788           0   \n",
            "6   2023-09-27        0   -0.378788           0   \n",
            "7   2023-10-04        0   -0.378788           0   \n",
            "8   2023-10-05        1    1.242424           1   \n",
            "9   2023-10-05        1    0.621212           1   \n",
            "10  2023-10-05        1    1.242424           1   \n",
            "11  2023-10-06        0   -0.378788           0   \n",
            "12  2023-10-06        0   -0.443182           0   \n",
            "13  2023-10-06        0   -0.378788           0   \n",
            "14  2023-10-11        1    1.530303           1   \n",
            "15  2023-10-11        1    1.530303           1   \n",
            "16  2023-10-11        1    0.724747           1   \n",
            "17  2023-10-11        1    0.512987           1   \n",
            "18  2023-10-11        1    0.621212           1   \n",
            "19  2023-10-11        1    0.621212           1   \n",
            "20  2023-10-11        1    0.621212           1   \n",
            "21  2023-10-11        1    0.621212           1   \n",
            "22  2023-10-11        1    0.724747           1   \n",
            "23  2023-10-12        0   -0.757576           0   \n",
            "24  2023-10-12        0   -0.757576           0   \n",
            "25  2023-10-12        0   -0.378788           0   \n",
            "26  2023-10-12        0   -0.338384           0   \n",
            "27  2023-10-12        0   -0.297980           0   \n",
            "28  2023-10-13        0   -0.541667           0   \n",
            "29  2023-10-13        0   -0.378788           0   \n",
            "30  2023-10-13        0   -0.547138           0   \n",
            "31  2023-10-13        0   -0.541667           0   \n",
            "32  2023-10-13        0   -0.378788           0   \n",
            "33  2023-10-13        0   -0.568182           0   \n",
            "34  2023-10-13        0   -0.473485           0   \n",
            "35  2023-10-13        0   -0.378788           0   \n",
            "36  2023-10-13        0   -0.378788           0   \n",
            "37  2023-10-13        0   -0.505051           0   \n",
            "38  2023-10-13        0   -0.378788           0   \n",
            "\n",
            "                                       title  \\\n",
            "0                      삼성전자, 3주만에 다시 '6만전자'로   \n",
            "1                      삼성전자, 3주만에 다시 '6만전자'로   \n",
            "2                   수요와 균형 이루는 주택공급 확대 정책 기대   \n",
            "3              주택구입자 3분의1이 받은 특례보금자리론…축소 파장은   \n",
            "4                도생·오피스텔에 기금 지원…공급부족 해소 도움될까   \n",
            "5                사라 버튼 떠나는 알렉산더 맥퀸, 후임 누가 될까   \n",
            "6                         이더리움 NFT가 지갑이 된다고?   \n",
            "7                    디폴트옵션 완전정복…당신도 연금부자 됩니다   \n",
            "8                  IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "9           \"에코프로 욕하려면 80만원 내세요\"…확 달라진 '종토방'   \n",
            "10                 IPO 대어 두산로보틱스, 상장 첫날 ‘따블’   \n",
            "11               80~1000만원대까지…시선강탈 레드카펫 ★드레스   \n",
            "12           \"모두 백인 남성이네\" 명품기업 케링그룹, 욕 먹는 이유   \n",
            "13                빗썸 수수료 무료, 830 프로젝트 덕분이라고?   \n",
            "14               삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "15               삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세   \n",
            "16                       [데스크칼럼]먹거리 물가와 기후위기   \n",
            "17        \"억눌렸던 욕구 폭발\"…뉴진스 '팝업스토어' 대박 이유 있었다   \n",
            "18         '목욕탕 슬리퍼'가 11조원 회사로…200년을 버틴 버켄스탁   \n",
            "19           뉴:홈, 당첨일 다르면 중복청약 OK…거주 의무도 꼼꼼히   \n",
            "20              마곡 3억·하남 4억대 ‘뉴홈’ 3300가구 풀린다   \n",
            "21                 같이 오르내리던 매매·전세가, 이제 동행 끝?   \n",
            "22           고조되는 이-팔 전쟁 우려, 코인은 정말 위기에 강한가?   \n",
            "23             \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "24             \"나만의 계획 있어\"…최태원이 구상하는 후계 구도는?   \n",
            "25         \"클수록 좋다\" SUV 판매 1위는 쏘렌토…파업 리스크 변수   \n",
            "26              지방소멸 해법 떠오른 다주택자 규제…패러다임 바뀌나   \n",
            "27            청계천 떠난 '작은 공장'이 말하는 떠나야만 했던 이유   \n",
            "28     \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "29                     포르셰 뽑은 30대, 인천서 확 늘었다   \n",
            "30  뉴욕증시, 예상 웃돈 CPI·국채금리 상승에 일제 하락…테슬라 1.5%↓   \n",
            "31     \"'반·배' 땡큐\" 美中서 모두 환호…LS일렉, 2년만 영업익 2배   \n",
            "32            한국 AI 경쟁력 세계 6위?…하위 굳히는 핵심 영역은   \n",
            "33               '미 국채가 안 팔린다'…증시 흔든 채권금리 급등   \n",
            "34           코스피, 美 CPI 부담에 1% 하락…2456.15 마감   \n",
            "35         '엔씨소프트 vs 카카오' 국민 밉상주 투표 열렸다…결과는?   \n",
            "36             550억에 인수하더니…'마흔살' KFC의 놀라운 변신   \n",
            "37            좀처럼 안 잡히는 美 고물가...연내 금리 추가 인상?   \n",
            "38                  분양가 너무 비쌌나…서울서 미분양 나온 까닭   \n",
            "\n",
            "                                    nouns  \n",
            "0                        삼성, 전자, 주, 다시, 로  \n",
            "1                        삼성, 전자, 주, 다시, 로  \n",
            "2              수요, 균형, 주택, 공급, 확대, 정책, 기대  \n",
            "3          주택, 구입, 이, 특례, 보금자리, 론, 축소, 파장  \n",
            "4        도생, 오피스텔, 기금, 지원, 공급, 부족, 해소, 도움  \n",
            "5                사라, 버튼, 알렉산더, 맥퀸, 후임, 누가  \n",
            "6                               더, 리움, 지갑  \n",
            "7             디폴트, 옵션, 완전, 정복, 당신, 연금, 부자  \n",
            "8                    두산, 로보틱스, 상장, 첫날, 따블  \n",
            "9                 에코, 프로, 욕, 내세, 확, 종, 토방  \n",
            "10                   두산, 로보틱스, 상장, 첫날, 따블  \n",
            "11                      시선, 강탈, 레드카펫, 드레스  \n",
            "12      모두, 백인, 남성, 명품, 기업, 케링, 그룹, 욕, 이유  \n",
            "13                  빗썸, 수수료, 무료, 프로젝트, 덕분  \n",
            "14           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "15           삼성, 전자, 조, 단위, 영업, 익, 복귀, 강세  \n",
            "16               데스크, 칼럼, 먹거리, 물가, 기후, 위기  \n",
            "17           욕구, 폭발, 뉴진스, 팝업, 스토어, 대박, 이유  \n",
            "18                     목욕탕, 슬리퍼, 회사, 버켄스탁  \n",
            "19            뉴, 홈, 당첨, 일, 중복, 청약, 거주, 의무  \n",
            "20                         마곡, 하남, 뉴홈, 가구  \n",
            "21                      매매, 전세, 이제, 동행, 끝  \n",
            "22           고조, 이, 팔, 전쟁, 우려, 코인, 정말, 위기  \n",
            "23                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "24                 나, 계획, 최태원, 구상, 후계, 구도  \n",
            "25                판매, 위, 쏘렌토, 파업, 리스크, 변수  \n",
            "26               지방, 소멸, 해법, 주택, 규제, 패러다임  \n",
            "27                      청계천, 공장, 이, 말, 이유  \n",
            "28          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "29                             포르셰, 인천, 확  \n",
            "30  뉴욕증시, 예상, 웃돈, 국채, 금리, 상승, 일제, 하락, 테슬라  \n",
            "31          반, 배, 땡큐, 모두, 환호, 렉, 영업, 익, 배  \n",
            "32             한국, 경쟁력, 세계, 위, 하위, 핵심, 영역  \n",
            "33              국채, 안, 린다, 증시, 채권, 금리, 급등  \n",
            "34                        코스피, 부담, 하락, 마감  \n",
            "35             엔씨소프트, 카카오, 국민, 상주, 투표, 결과  \n",
            "36                           인수, 살, 의, 변신  \n",
            "37             좀처럼, 안, 고물, 연내, 금리, 추가, 인상  \n",
            "38                         분양, 서울, 미분, 까닭  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델링\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. 데이터 준비\n",
        "X_data = merged_df['nouns'].apply(lambda x: ' '.join([word for word in x.split(', ') if len(word) > 1])).values\n",
        "Y_data = merged_df['sent_label'].values  # 기존의 'merged_df'를 사용\n",
        "\n",
        "# 2. 토큰화 및 패딩\n",
        "vocab_size = 2000\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(X_data)\n",
        "X_tokenized = tokenizer.texts_to_sequences(X_data)\n",
        "X_padded = pad_sequences(X_tokenized, maxlen=30)\n",
        "\n",
        "# 3. Bi-LSTM 모델 구축 및 훈련\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_padded, Y_data, epochs=15, callbacks=[es, mc], batch_size=256, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRO0d5yn2mjQ",
        "outputId": "87de05c8-c2bd-466a-8cce-7daebbc4e482"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.4194\n",
            "Epoch 1: val_acc improved from -inf to 1.00000, saving model to best_model.h5\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.6937 - acc: 0.4194 - val_loss: 0.6604 - val_acc: 1.0000\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6911 - acc: 0.5161\n",
            "Epoch 2: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6911 - acc: 0.5161 - val_loss: 0.6604 - val_acc: 1.0000\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6893 - acc: 0.5161\n",
            "Epoch 3: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6893 - acc: 0.5161 - val_loss: 0.6599 - val_acc: 1.0000\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6874 - acc: 0.5161\n",
            "Epoch 4: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.6874 - acc: 0.5161 - val_loss: 0.6594 - val_acc: 1.0000\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6853 - acc: 0.5161\n",
            "Epoch 5: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.6853 - acc: 0.5161 - val_loss: 0.6589 - val_acc: 1.0000\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6829 - acc: 0.5161\n",
            "Epoch 6: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.6829 - acc: 0.5161 - val_loss: 0.6584 - val_acc: 1.0000\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6802 - acc: 0.5161\n",
            "Epoch 7: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.6802 - acc: 0.5161 - val_loss: 0.6578 - val_acc: 1.0000\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6769 - acc: 0.5161\n",
            "Epoch 8: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6769 - acc: 0.5161 - val_loss: 0.6571 - val_acc: 1.0000\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6731 - acc: 0.5806\n",
            "Epoch 9: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6731 - acc: 0.5806 - val_loss: 0.6563 - val_acc: 1.0000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6685 - acc: 0.7419\n",
            "Epoch 10: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6685 - acc: 0.7419 - val_loss: 0.6555 - val_acc: 1.0000\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6630 - acc: 0.8065\n",
            "Epoch 11: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.6630 - acc: 0.8065 - val_loss: 0.6545 - val_acc: 1.0000\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6563 - acc: 0.8710\n",
            "Epoch 12: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6563 - acc: 0.8710 - val_loss: 0.6535 - val_acc: 1.0000\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6483 - acc: 0.9032\n",
            "Epoch 13: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6483 - acc: 0.9032 - val_loss: 0.6523 - val_acc: 1.0000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6387 - acc: 0.9355\n",
            "Epoch 14: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6387 - acc: 0.9355 - val_loss: 0.6508 - val_acc: 1.0000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6270 - acc: 0.9355\n",
            "Epoch 15: val_acc did not improve from 1.00000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.6270 - acc: 0.9355 - val_loss: 0.6489 - val_acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최신 뉴스 크롤링 후 모델에 적용해서 최종 결과 확\n",
        "\n",
        "# 뉴스 제목 크롤링\n",
        "base_url = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101&date=\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "start_date = datetime.datetime.now() - datetime.timedelta(days=30)\n",
        "end_date = datetime.datetime.now() - datetime.timedelta(days=5)\n",
        "current_date = start_date\n",
        "\n",
        "news_data = []\n",
        "\n",
        "while current_date <= end_date:\n",
        "    response = requests.get(base_url + current_date.strftime('%Y%m%d'), headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    for item in soup.select(\".cluster_text a\"):\n",
        "        title = item.text.strip()\n",
        "        news_data.append({\n",
        "            'date': current_date.strftime('%Y-%m-%d'),\n",
        "            'title': title\n",
        "        })\n",
        "    current_date += datetime.timedelta(days=1)\n",
        "\n",
        "news_df = pd.DataFrame(news_data, columns=['date', 'title'])\n",
        "\n",
        "# 명사 추출\n",
        "okt = Okt()\n",
        "news_df['nouns'] = news_df['title'].apply(lambda x: ', '.join(okt.nouns(x)))\n",
        "\n",
        "# 감성 사전과 비교하여 감성 점수 계산\n",
        "news_df['filtered_nouns'] = news_df['nouns'].apply(lambda x: [word for word in x.split(', ') if len(word) > 1])\n",
        "news_df['sent_score'] = news_df['filtered_nouns'].apply(calculate_sentiment_score)  # 이전에 정의한 함수\n",
        "\n",
        "# 예측을 위한 데이터 전처리\n",
        "X_test_tokenized = tokenizer.texts_to_sequences(news_df['nouns'].apply(lambda x: ' '.join([word for word in x.split(', ') if len(word) > 1])).values)\n",
        "X_test_padded = pad_sequences(X_test_tokenized, maxlen=30)\n",
        "\n",
        "# 훈련된 Bi-LSTM 모델로 예측\n",
        "predicted = model.predict(X_test_padded)\n",
        "news_df['predicted_label'] = (predicted > 0.5).astype(int)\n",
        "\n",
        "# 결과 출력\n",
        "positive_news_ratio = news_df['predicted_label'].sum() / len(news_df)\n",
        "if positive_news_ratio > 0.5:\n",
        "    print(\"미래 주식 시장은 긍정적으로 움직일 것으로 예상됩니다.\")\n",
        "else:\n",
        "    print(\"미래 주식 시장은 부정적으로 움직일 것으로 예상됩니다.\")\n",
        "\n",
        "    # 각 뉴스의 감성 점수를 바탕으로 긍정적 및 부정적 뉴스 개수 확인 및 출력\n",
        "sent_mean = news_df['sent_score'].mean()\n",
        "\n",
        "pos_news = len(news_df[news_df['sent_score'] > sent_mean])\n",
        "neg_news = len(news_df[news_df['sent_score'] <= sent_mean])\n",
        "total_news = len(news_df)\n",
        "\n",
        "print(f\"긍정적 뉴스 수: {pos_news} ({pos_news/total_news*100:.2f}%)\")\n",
        "print(f\"부정적 뉴스 수: {neg_news} ({neg_news/total_news*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n긍정적 뉴스 예시:\")\n",
        "for title in news_df[news_df['sent_score'] > sent_mean]['title'].head(5):\n",
        "    print(\"-\", title)\n",
        "\n",
        "print(\"\\n부정적 뉴스 예시:\")\n",
        "for title in news_df[news_df['sent_score'] <= sent_mean]['title'].head(5):\n",
        "    print(\"-\", title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk8lboFM2vfR",
        "outputId": "fdad5ec3-0e50-4702-966a-b83fb87243e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 19ms/step\n",
            "미래 주식 시장은 부정적으로 움직일 것으로 예상됩니다.\n",
            "긍정적 뉴스 수: 21 (20.19%)\n",
            "부정적 뉴스 수: 83 (79.81%)\n",
            "\n",
            "긍정적 뉴스 예시:\n",
            "- 뉴:홈, 당첨일 다르면 중복청약 OK…거주 의무도 꼼꼼히\n",
            "- 마곡 3억·하남 4억대 ‘뉴홈’ 3300가구 풀린다\n",
            "- 청약 경쟁률 수십대 1인데…왜 '완판'은 안될까?\n",
            "- 삼성전자,한 달 만에 ‘7만전자’복귀\n",
            "- 삼성전자, 3분기 ‘조 단위’ 영업익 복귀에 강세\n",
            "\n",
            "부정적 뉴스 예시:\n",
            "- 만기가 돌아왔다…갈아타기 고민하는 예테크족\n",
            "- 디폴트옵션 완전정복…당신도 연금부자 됩니다\n",
            "- \"차량 3대면 주차비 20만원 내세요\" 주차난에 차등 요금 도입 단지↑\n",
            "- 치솟는 강남권 초소형 아파트 인기… 일부 단지 신고가 근접\n",
            "- “MZ는 주택시장 풍향계?”…서울집 내다 파는 2030 늘고, 영끌족 줄어\n"
          ]
        }
      ]
    }
  ]
}